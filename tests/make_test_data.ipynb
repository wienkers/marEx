{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getuser\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import intake\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import marEx\n",
    "import marEx.helper as hpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lustre Scratch Directory\n",
    "scratch_dir = Path(\"/scratch\") / getuser()[0] / getuser()\n",
    "save_dir = Path(\"/home\") / getuser()[0] / getuser() / \"opt\" / \"marEx\" / \"tests\" / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Dask Cluster\n",
    "client = hpc.start_local_cluster(\n",
    "    n_workers=16, threads_per_worker=1, scratch_dir=scratch_dir / \"clients\"\n",
    ")  # Specify temporary scratch directory for dask to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125a04b",
   "metadata": {},
   "source": [
    "# Raw SST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc76bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog(\"https://raw.githubusercontent.com/eerie-project/intake_catalogues/main/eerie.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 40 years of OSTIA Observations\n",
    "dat_regrid = cat[\"dkrz.disk.observations.OSTIA.OSTIA.daily\"]\n",
    "sst_regrid = dat_regrid(chunks={}).to_dask().sst.astype(np.float32).coarsen(lat=5, lon=5).mean().rename(\"to\")\n",
    "sst_regrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 40 years of Daily ICON data (ref. EERIE project)\n",
    "dat_native = cat[\"dkrz.disk.model-output.icon-esm-er.eerie-control-1950.v20240618\"][\"ocean\"][\"native\"]\n",
    "sst_native = (\n",
    "    dat_native[\"2d_daily_mean\"](chunks={}).to_dask().to.isel(depth=0).drop_vars({\"depth\", \"cell_sea_land_mask\"}).chunk({\"time\": 32})\n",
    ")\n",
    "sst_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subset\n",
    "time_slice_ostia = slice(\"1982-01-01\", \"2022-01-01\")\n",
    "time_slice_icon = slice(\"1991-01-01\", \"2031-01-01\")\n",
    "regrid_slice_ostia = dict(lat=slice(35, 40), lon=slice(-40, -30))\n",
    "native_slice_icon = dict(lat=slice(39, 40), lon=slice(-40, -39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fb398",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_regrid_slice = sst_regrid.sel(time=time_slice_ostia, **regrid_slice_ostia).chunk({\"time\": 30, \"lat\": -1, \"lon\": -1})\n",
    "sst_regrid_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1841dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sst_native_slice = sst_native.sel(time=time_slice_icon).sel(**native_slice_icon).drop_vars({\"lat\", \"lon\"})\n",
    "sst_native_slice = sst_native.sel(time=time_slice_icon)\n",
    "sst_native_slice = sst_native_slice.where(\n",
    "    ((sst_native_slice.lat.compute() > 39) & (sst_native_slice.lat.compute() < 40))\n",
    "    & ((sst_native_slice.lon.compute() > -40) & (sst_native_slice.lon.compute() < -39)),\n",
    "    drop=True,\n",
    ").drop_vars({\"lat\", \"lon\"})\n",
    "sst_native_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5062d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Zarr\n",
    "# sst_regrid_slice.to_zarr(save_dir / \"sst_gridded.zarr\", mode=\"w\")\n",
    "sst_native_slice.to_zarr(save_dir / \"sst_unstructured.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66b2d3",
   "metadata": {},
   "source": [
    "# Pre-processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc21e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = slice(\"2010-01-01\", \"2010-02-01\")\n",
    "extremes_ds = (\n",
    "    xr.open_zarr(scratch_dir / \"mhws\" / \"extremes_binary_gridded_shifting_hobday.zarr\", chunks={})\n",
    "    .sel(time=time_slice)\n",
    "    .drop_vars({\"thresholds\", \"dat_anomaly\", \"dayofyear\"})\n",
    ")\n",
    "extremes_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0717987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarsen extremes_ds (lat & lon)\n",
    "extremes_ds_coarsen = extremes_ds.coarsen(lat=4, lon=4, boundary=\"trim\").any().chunk({\"time\": 2, \"lat\": -1, \"lon\": -1}).persist()\n",
    "extremes_ds_coarsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_ds_coarsen[\"lat\"] = extremes_ds_coarsen[\"lat\"].astype(np.float32)\n",
    "extremes_ds_coarsen[\"lon\"] = extremes_ds_coarsen[\"lon\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear encoding so we can write to Zarr\n",
    "extremes_ds_coarsen.encoding = {}\n",
    "for var in extremes_ds_coarsen.data_vars:\n",
    "    extremes_ds_coarsen[var].encoding = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_ds_coarsen.to_zarr(save_dir / \"extremes_gridded.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233486f",
   "metadata": {},
   "source": [
    "### Make version with artificial blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4456d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_ds_coarsen_blob = extremes_ds_coarsen.copy(deep=True)\n",
    "extremes_ds_coarsen_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e663d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 3  # degrees east per day\n",
    "start_lon = 170\n",
    "\n",
    "delta_t = extremes_ds_coarsen_blob.time - extremes_ds_coarsen_blob.time.min()\n",
    "delta_t = delta_t.dt.days\n",
    "delta_t\n",
    "\n",
    "offset_east = delta_t * rate\n",
    "\n",
    "centroid_lat = delta_t * 0.0  # No movement in latitude\n",
    "centroid_lon = start_lon + offset_east"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf52e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each time, create the square blob\n",
    "blob_size = 7  # degrees\n",
    "\n",
    "lon_0_360 = xr.where(extremes_ds_coarsen_blob.lon >= 0, extremes_ds_coarsen_blob.lon, extremes_ds_coarsen_blob.lon + 360)\n",
    "\n",
    "extreme_events_blob = np.zeros_like(extremes_ds_coarsen_blob[\"extreme_events\"].compute().values, dtype=bool)\n",
    "\n",
    "for i in range(len(extremes_ds_coarsen_blob.time)):\n",
    "    # Create a square blob\n",
    "    lat_min = centroid_lat[i] - blob_size / 2\n",
    "    lat_max = centroid_lat[i] + blob_size / 2\n",
    "    lon_min = centroid_lon[i] - blob_size / 2\n",
    "    lon_max = centroid_lon[i] + blob_size / 2\n",
    "\n",
    "    # Create the mask, accounting for the range of lon from [-180, 180]\n",
    "    mask = (\n",
    "        (extremes_ds_coarsen_blob.lat >= lat_min)\n",
    "        & (extremes_ds_coarsen_blob.lat <= lat_max)\n",
    "        & (lon_0_360 >= lon_min)\n",
    "        & (lon_0_360 <= lon_max)\n",
    "    )\n",
    "\n",
    "    # Set the mask to True for the blob\n",
    "    extreme_events_blob[i, mask] = True\n",
    "\n",
    "# Assign the modified blob back to the dataset\n",
    "extremes_ds_coarsen_blob[\"extreme_events\"] = ((\"time\", \"lat\", \"lon\"), extreme_events_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d69a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_ds_coarsen_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42166205",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_ds_coarsen_blob.to_zarr(save_dir / \"extremes_gridded_blob.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7b207",
   "metadata": {},
   "source": [
    "# Make Pre-processed Native Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog(\"https://raw.githubusercontent.com/eerie-project/intake_catalogues/main/eerie.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64194971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 40 years of Daily ICON data (ref. EERIE project)\n",
    "dat_native = cat[\"dkrz.disk.model-output.icon-esm-er.eerie-control-1950.v20240618\"][\"ocean\"][\"native\"]\n",
    "sst_native = (\n",
    "    dat_native[\"2d_daily_mean\"](chunks={}).to_dask().to.isel(depth=0).drop_vars({\"depth\", \"cell_sea_land_mask\"}).chunk({\"time\": 32})\n",
    ")\n",
    "sst_native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice_icon = slice(\"2000-01-01\", \"2002-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_native_slice = sst_native.sel(time=time_slice_icon)  # .isel(ncells=native_slice_icon)\n",
    "sst_native_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2d = dat_native[\"2d_grid\"](chunks={}).to_dask().rename({\"cell\": \"ncells\"})\n",
    "neighbours = grid2d.neighbor_cell_index.rename({\"clat\": \"lat\", \"clon\": \"lon\"})\n",
    "areas = grid2d.cell_area.rename({\"clat\": \"lat\", \"clon\": \"lon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54712e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_native_slice = sst_native_slice.chunk({\"ncells\": 100000})\n",
    "sst_native_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2afffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data using `MarEx Detect` helper functions:\n",
    "\n",
    "extremes_ds = marEx.preprocess_data(\n",
    "    sst_native_slice,\n",
    "    threshold_percentile=95,  # Use the 95th percentile as the extremes threshold\n",
    "    dask_chunks={\n",
    "        \"time\": 2\n",
    "    },  # Dask chunks for *output* data (this is much smaller than the input chunks because the Tracking/ID is more memory-intensive)\n",
    "    neighbours=neighbours,  # Pass information about neighbours to be used in subsequent processing\n",
    "    cell_areas=areas,  # Pass information about each Unstructured Grid's cell area (in metres) to be used in subsequent processing\n",
    "    dimensions={\"time\": \"time\", \"xdim\": \"ncells\"},\n",
    ")  # Not specifying 'ydim' tells MarEx-Detect that it is an Unstructured Grid\n",
    "extremes_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728496bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_cells = 500\n",
    "# native_slice_icon = slice(0, N_cells)\n",
    "# extremes_subset = xr.load_dataset(scratch_dir / \"mhws\" / \"extremes_unstructured_small.zarr\", chunks={}).isel(\n",
    "#     ncells=native_slice_icon\n",
    "# )\n",
    "# extremes_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45690bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_ds = xr.load_dataset(scratch_dir / \"mhws\" / \"extremes_unstructured_small.zarr\", chunks={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_ds_index = extremes_ds.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a557d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new variable (in the dimension \"ncells\") which is just the value of the `ncells` index\n",
    "extremes_ds_index[\"ncells_original\"] = extremes_ds_index[\"ncells\"]\n",
    "extremes_ds_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce16d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset = extremes_ds_index.where(\n",
    "    ((extremes_ds.lat.compute() > 39) & (extremes_ds.lat.compute() < 40))\n",
    "    & ((extremes_ds.lon.compute() > -40) & (extremes_ds.lon.compute() < -39)),\n",
    "    drop=True,\n",
    ")\n",
    "extremes_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set all neighbours > N_cells to be 0\n",
    "# extremes_subset[\"neighbours\"] = extremes_subset.neighbours.where(extremes_subset.neighbours <= N_cells, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb91a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For each value in `extremes_subset.neighbours`, set the value to 0 if the value does not exist in extremes_subset.ncells\n",
    "# extremes_subset[\"neighbours\"] = extremes_subset.neighbours.where(extremes_subset.neighbours.isin(extremes_subset.ncells_original+1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a mapping from extremes_subset.ncells_original --> extremes_subset.ncells\n",
    "mapping = dict(zip(extremes_subset.ncells_original.values, extremes_subset.ncells.values))\n",
    "\n",
    "# Function to map neighbour indices\n",
    "\n",
    "\n",
    "def remap_neighbours(neigh):\n",
    "    # If neighbour is 0 or not in mapping, return 0\n",
    "    return mapping.get(neigh, 0) if neigh != 0 else 0\n",
    "\n",
    "\n",
    "# Vectorise the function for use with xarray\n",
    "remap_vec = np.vectorize(remap_neighbours)\n",
    "\n",
    "# Apply remapping to the neighbours variable\n",
    "extremes_subset[\"neighbours\"] = (extremes_subset[\"neighbours\"].dims, remap_vec(extremes_subset[\"neighbours\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset[\"lat\"] = extremes_subset[\"lat\"].astype(np.float32)\n",
    "extremes_subset[\"lon\"] = extremes_subset[\"lon\"].astype(np.float32)\n",
    "extremes_subset[\"thresholds\"] = extremes_subset[\"thresholds\"].astype(np.float32)\n",
    "extremes_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1beed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset[\"neighbours\"] = extremes_subset[\"neighbours\"].astype(np.int32)\n",
    "extremes_subset[\"cell_areas\"] = extremes_subset[\"cell_areas\"].astype(np.float32)\n",
    "extremes_subset[\"mask\"] = extremes_subset[\"mask\"].astype(np.bool_)\n",
    "extremes_subset[\"extreme_events\"] = extremes_subset[\"extreme_events\"].astype(np.bool_)\n",
    "extremes_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset = extremes_subset.isel(time=slice(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb5f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset = extremes_subset.drop_vars(\"ncells_original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset.to_zarr(save_dir / \"extremes_unstructured.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc37e00",
   "metadata": {},
   "source": [
    "# Make Artificial Merging Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset = xr.load_dataset(save_dir / \"extremes_unstructured.zarr\", chunks={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_events = extremes_subset.extreme_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the blobs\n",
    "size1 = 0.2  # degrees\n",
    "size2 = 0.2  # degrees\n",
    "\n",
    "# Start/end positions for the blobs (choose within your region)\n",
    "lat1_start, lon1_start = 39.1, -39.8\n",
    "lat2_start, lon2_start = 39.9, -39.2\n",
    "lat1_end, lon1_end = 39.5, -39.5\n",
    "lat2_end, lon2_end = 39.5, -39.5\n",
    "\n",
    "n_times = 20  # extremes_subset.dims[\"time\"]\n",
    "\n",
    "# Linearly interpolate positions for each blob\n",
    "lat1_traj = np.linspace(lat1_start, lat1_end, n_times)\n",
    "lon1_traj = np.linspace(lon1_start, lon1_end, n_times)\n",
    "lat2_traj = np.linspace(lat2_start, lat2_end, n_times)\n",
    "lon2_traj = np.linspace(lon2_start, lon2_end, n_times)\n",
    "\n",
    "# Get cell centers\n",
    "cell_lats = extremes_subset[\"lat\"].values\n",
    "cell_lons = extremes_subset[\"lon\"].values\n",
    "\n",
    "# Prepare a new array for the blobs\n",
    "blobs = np.zeros_like(extremes_subset[\"extreme_events\"].values, dtype=bool)\n",
    "\n",
    "for t in range(n_times):\n",
    "    # Blob 1 mask\n",
    "    mask1 = (np.abs(cell_lats - lat1_traj[t]) <= size1 / 2) & (np.abs(cell_lons - lon1_traj[t]) <= size1 / 2)\n",
    "    # Blob 2 mask\n",
    "    mask2 = (np.abs(cell_lats - lat2_traj[t]) <= size2 / 2) & (np.abs(cell_lons - lon2_traj[t]) <= size2 / 2)\n",
    "    # Set blobs\n",
    "    blobs[t, mask1] = True\n",
    "    blobs[t, mask2] = True\n",
    "\n",
    "# Assign the new blobs to extreme_events\n",
    "extremes_subset[\"extreme_events\"] = ((\"time\", \"ncells\"), blobs + previous_events.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7403d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_subset.to_zarr(save_dir / \"extremes_unstructured_merging.zarr\", mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
