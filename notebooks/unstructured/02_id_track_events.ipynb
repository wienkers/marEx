{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7d3a1a",
   "metadata": {},
   "source": [
    "# Identify & Track Marine Heatwaves on _Unstructured Grid_ using `spot_the_blOb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61028733",
   "metadata": {},
   "source": [
    "## Processing Steps:\n",
    "1. Fill spatial holes in the binary data, using `dask_image.ndmorph` -- up to `R_fill` cells in radius.\n",
    "2. Fill gaps in time -- permitting up to `T_fill` missing time slices, while keeping the same blob ID.\n",
    "3. Filter out small objects -- area less than the bottom `area_filter_quartile` of the size distribution of objects.\n",
    "4. Identify objects in the binary data, using `dask_image.ndmeasure`.\n",
    "5. Connect objects across time, applying the following criteria for splitting, merging, and persistence:\n",
    "    - Connected Blobs must overlap by at least fraction `overlap_threshold` of the smaller blob.\n",
    "    - Merged Blobs retain their original ID, but partition the child blob based on the parent of the _nearest-neighbour_ cell. \n",
    "6. Cluster and reduce the final object ID graph using `scipy.sparse.csgraph.connected_components`.\n",
    "7. Map the tracked objects into ID-time space for convenient analysis.\n",
    "\n",
    "N.B.: Exploits parallelised `dask` operations with optimised chunking using `flox` for memory efficiency and speed \\\n",
    "N.N.B.: This example using 40 years of _daily_ outputs at 5km resolution on an Unstructured Grid (15 million cells) using 32 cores takes \n",
    "- Full Split/Merge Thresholding & Merge Tracking:  ~40 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b337539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "from getpass import getuser\n",
    "from pathlib import Path\n",
    "\n",
    "import spot_the_blOb as blob\n",
    "import spot_the_blOb.helper as hpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310fd2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory per Worker: 20.15 GB\n",
      "Hostname is  l40350\n",
      "Forward Port = l40350:8787\n",
      "Dashboard Link: localhost:8787/status\n"
     ]
    }
   ],
   "source": [
    "# Start Dask Cluster\n",
    "#  N.B.: Need ~ 8 GB per worker (for 5km data // 15 million points)\n",
    "client = hpc.StartLocalCluster(n_workers=25, n_threads=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a21e23-427a-4f6f-9a91-fa2ae628f148",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Pre-processed Data (cf. `01_preprocess_extremes.ipynb`)\n",
    "\n",
    "file_name = Path('/scratch') / getuser()[0] / getuser() / 'mhws' / 'extreme_events_binary_unstruct.zarr'\n",
    "chunk_size = {'time': 4, 'ncells': -1}\n",
    "ds = xr.open_zarr(str(file_name), chunks={}).isel(time=slice(0, 64)).chunk(chunk_size) #128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff7e8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking Parameters\n",
    "\n",
    "drop_area_quartile = 0.8  # Remove the smallest 80% of the identified blobs\n",
    "hole_filling_radius = 32  # Fill small holes with radius < 32 elements, i.e. ~100 km\n",
    "time_gap_fill = 2         # Allow gaps of 4 days and still continue the blob tracking with the same ID\n",
    "allow_merging = True      # Allow blobs to split/merge. Keeps track of merge events & unique IDs.\n",
    "overlap_threshold = 0.5   # Overlap threshold for merging blobs. If overlap < threshold, blobs keep independent IDs.\n",
    "nn_partitioning = True    # Use new NN method to partition merged children blobs. If False, reverts to old method of Di Sun et al. 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Constructing the Sparse Dilation Matrix.\n",
      "Finished Filling Spatial Holes\n",
      "Finished Filling Spatio-temporal Holes.\n",
      "Finished Filtering Small Blobs.\n",
      "Finished Blob Identification.\n",
      "Finished Making Blobs Globally Unique.\n",
      "Finished Calculating Blob Properties.\n",
      "Finished Finding Overlapping Blobs.\n",
      "Processing Parallel Iteration 1 with 11 Merging Blobs...\n",
      "  Finished Mapping Children to Time Indices.\n",
      "  Finished Batch Processing Step.\n",
      "  Finished Consolidation Step 1: Temporary ID Mapping\n",
      "  Finished Consolidation Step 2: Data Field Update.\n",
      "  Finished Consolidation Step 3: Merge List Dictionary Consolidation.\n",
      "Processing Parallel Iteration 2 with 9 Merging Blobs...\n",
      "  Finished Mapping Children to Time Indices.\n",
      "  Finished Batch Processing Step.\n",
      "  Finished Consolidation Step 1: Temporary ID Mapping\n",
      "  Finished Consolidation Step 2: Data Field Update.\n",
      "  Finished Consolidation Step 3: Merge List Dictionary Consolidation.\n",
      "Processing Parallel Iteration 3 with 2 Merging Blobs...\n",
      "  Finished Mapping Children to Time Indices.\n",
      "  Finished Batch Processing Step.\n",
      "  Finished Consolidation Step 1: Temporary ID Mapping\n",
      "  Finished Consolidation Step 2: Data Field Update.\n",
      "  Finished Consolidation Step 3: Merge List Dictionary Consolidation.\n",
      "  Refreshing Dask Task Graph...\n",
      "Finished Splitting and Merging Blobs.\n",
      "Finished Clustering and Renaming Blobs.\n",
      "Finished Tracking All Blobs ! \n",
      "\n",
      "\n",
      "Tracking Statistics:\n",
      "   Binary Hobday to Processed Area Fraction: 0.7691209876330218\n",
      "   Total Object Area IDed (cells): 59759044\n",
      "   Number of Initial Pre-Filtered Blobs: 3405\n",
      "   Area Cutoff Threshold (cells): 19152\n",
      "   Accepted Area Fraction: 0.7985329049105939\n",
      "   Total Blobs Tracked: 84\n",
      "   Total Merging Events Recorded: 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 4GB\n",
       "Dimensions:       (time: 64, ncells: 14886338, ID: 85, component: 2,\n",
       "                   sibling_ID: 3)\n",
       "Coordinates:\n",
       "  * time          (time) datetime64[ns] 512B 2002-04-11T23:59:00 ... 2002-06-...\n",
       "  * ID            (ID) int32 340B 1 2 3 4 5 6 7 8 9 ... 78 79 80 81 82 83 84 85\n",
       "Dimensions without coordinates: ncells, component, sibling_ID\n",
       "Data variables:\n",
       "    ID_field      (time, ncells) int32 4GB dask.array&lt;chunksize=(4, 14886338), meta=np.ndarray&gt;\n",
       "    global_ID     (time, ID) int32 22kB dask.array&lt;chunksize=(4, 85), meta=np.ndarray&gt;\n",
       "    area          (time, ID) float32 22kB dask.array&lt;chunksize=(4, 85), meta=np.ndarray&gt;\n",
       "    centroid      (component, time, ID) float32 44kB dask.array&lt;chunksize=(2, 4, 85), meta=np.ndarray&gt;\n",
       "    presence      (time, ID) bool 5kB dask.array&lt;chunksize=(4, 85), meta=np.ndarray&gt;\n",
       "    time_start    (ID) datetime64[ns] 680B dask.array&lt;chunksize=(85,), meta=np.ndarray&gt;\n",
       "    time_end      (ID) datetime64[ns] 680B dask.array&lt;chunksize=(85,), meta=np.ndarray&gt;\n",
       "    merge_ledger  (time, ID, sibling_ID) int32 65kB dask.array&lt;chunksize=(4, 85, 3), meta=np.ndarray&gt;\n",
       "    lat           (ncells) float64 119MB dask.array&lt;chunksize=(14886338,), meta=np.ndarray&gt;\n",
       "    lon           (ncells) float64 119MB dask.array&lt;chunksize=(14886338,), meta=np.ndarray&gt;\n",
       "Attributes: (12/13)\n",
       "    allow_merging:               1\n",
       "    N_blobs_prefiltered:         3405\n",
       "    N_blobs_final:               84\n",
       "    R_fill:                      32\n",
       "    T_fill:                      2\n",
       "    area_filter_quartile:        0.8\n",
       "    ...                          ...\n",
       "    accepted_area_fraction:      0.7985329049105939\n",
       "    preprocessed_area_fraction:  0.7691209876330218\n",
       "    overlap_threshold:           0.5\n",
       "    nn_partitioning:             1\n",
       "    total_merges:                38\n",
       "    multi_parent_merges:         3</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-cc0f6dba-0948-46db-bbb1-355486c0aa5d' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-cc0f6dba-0948-46db-bbb1-355486c0aa5d' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 64</li><li><span>ncells</span>: 14886338</li><li><span class='xr-has-index'>ID</span>: 85</li><li><span>component</span>: 2</li><li><span>sibling_ID</span>: 3</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-795bba47-6aaf-45ea-9bd8-24a1f4cc8fb8' class='xr-section-summary-in' type='checkbox'  checked><label for='section-795bba47-6aaf-45ea-9bd8-24a1f4cc8fb8' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2002-04-11T23:59:00 ... 2002-06-...</div><input id='attrs-baf83898-f520-431e-adb5-016133de1e33' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-baf83898-f520-431e-adb5-016133de1e33' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9395fb6b-c27e-4110-b430-786585641d94' class='xr-var-data-in' type='checkbox'><label for='data-9395fb6b-c27e-4110-b430-786585641d94' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2002-04-11T23:59:00.000000000&#x27;, &#x27;2002-04-12T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-13T23:59:00.000000000&#x27;, &#x27;2002-04-14T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-15T23:59:00.000000000&#x27;, &#x27;2002-04-16T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-17T23:59:00.000000000&#x27;, &#x27;2002-04-18T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-19T23:59:00.000000000&#x27;, &#x27;2002-04-20T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-21T23:59:00.000000000&#x27;, &#x27;2002-04-22T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-23T23:59:00.000000000&#x27;, &#x27;2002-04-24T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-25T23:59:00.000000000&#x27;, &#x27;2002-04-26T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-27T23:59:00.000000000&#x27;, &#x27;2002-04-28T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-04-29T23:59:00.000000000&#x27;, &#x27;2002-04-30T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-01T23:59:00.000000000&#x27;, &#x27;2002-05-02T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-03T23:59:00.000000000&#x27;, &#x27;2002-05-04T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-05T23:59:00.000000000&#x27;, &#x27;2002-05-06T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-07T23:59:00.000000000&#x27;, &#x27;2002-05-08T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-09T23:59:00.000000000&#x27;, &#x27;2002-05-10T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-11T23:59:00.000000000&#x27;, &#x27;2002-05-12T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-13T23:59:00.000000000&#x27;, &#x27;2002-05-14T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-15T23:59:00.000000000&#x27;, &#x27;2002-05-16T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-17T23:59:00.000000000&#x27;, &#x27;2002-05-18T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-19T23:59:00.000000000&#x27;, &#x27;2002-05-20T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-21T23:59:00.000000000&#x27;, &#x27;2002-05-22T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-23T23:59:00.000000000&#x27;, &#x27;2002-05-24T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-25T23:59:00.000000000&#x27;, &#x27;2002-05-26T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-27T23:59:00.000000000&#x27;, &#x27;2002-05-28T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-29T23:59:00.000000000&#x27;, &#x27;2002-05-30T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-05-31T23:59:00.000000000&#x27;, &#x27;2002-06-01T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-06-02T23:59:00.000000000&#x27;, &#x27;2002-06-03T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-06-04T23:59:00.000000000&#x27;, &#x27;2002-06-05T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-06-06T23:59:00.000000000&#x27;, &#x27;2002-06-07T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-06-08T23:59:00.000000000&#x27;, &#x27;2002-06-09T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-06-10T23:59:00.000000000&#x27;, &#x27;2002-06-11T23:59:00.000000000&#x27;,\n",
       "       &#x27;2002-06-12T23:59:00.000000000&#x27;, &#x27;2002-06-13T23:59:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>ID</span></div><div class='xr-var-dims'>(ID)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>1 2 3 4 5 6 7 ... 80 81 82 83 84 85</div><input id='attrs-2042fb83-25d5-4435-8e5d-db914ec6b4ff' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2042fb83-25d5-4435-8e5d-db914ec6b4ff' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2869d0c5-9b95-4790-acd2-82c5ea716f1e' class='xr-var-data-in' type='checkbox'><label for='data-2869d0c5-9b95-4790-acd2-82c5ea716f1e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "       55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], dtype=int32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-37494fca-02c9-40cc-b37f-3ff47be99526' class='xr-section-summary-in' type='checkbox'  checked><label for='section-37494fca-02c9-40cc-b37f-3ff47be99526' class='xr-section-summary' >Data variables: <span>(10)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>ID_field</span></div><div class='xr-var-dims'>(time, ncells)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(4, 14886338), meta=np.ndarray&gt;</div><input id='attrs-9ae4470e-4a0d-41b3-80d5-a52eb3da3c21' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9ae4470e-4a0d-41b3-80d5-a52eb3da3c21' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ef88e7ea-683b-4270-be65-18d62e11986b' class='xr-var-data-in' type='checkbox'><label for='data-ef88e7ea-683b-4270-be65-18d62e11986b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 3.55 GiB </td>\n",
       "                        <td> 227.15 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (64, 14886338) </td>\n",
       "                        <td> (4, 14886338) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 16 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> int32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"1\" x2=\"120\" y2=\"1\" />\n",
       "  <line x1=\"0\" y1=\"3\" x2=\"120\" y2=\"3\" />\n",
       "  <line x1=\"0\" y1=\"4\" x2=\"120\" y2=\"4\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"120\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"7\" x2=\"120\" y2=\"7\" />\n",
       "  <line x1=\"0\" y1=\"9\" x2=\"120\" y2=\"9\" />\n",
       "  <line x1=\"0\" y1=\"11\" x2=\"120\" y2=\"11\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"120\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"14\" x2=\"120\" y2=\"14\" />\n",
       "  <line x1=\"0\" y1=\"15\" x2=\"120\" y2=\"15\" />\n",
       "  <line x1=\"0\" y1=\"17\" x2=\"120\" y2=\"17\" />\n",
       "  <line x1=\"0\" y1=\"19\" x2=\"120\" y2=\"19\" />\n",
       "  <line x1=\"0\" y1=\"20\" x2=\"120\" y2=\"20\" />\n",
       "  <line x1=\"0\" y1=\"22\" x2=\"120\" y2=\"22\" />\n",
       "  <line x1=\"0\" y1=\"23\" x2=\"120\" y2=\"23\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >14886338</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">64</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>global_ID</span></div><div class='xr-var-dims'>(time, ID)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(4, 85), meta=np.ndarray&gt;</div><input id='attrs-cd8d403a-b45c-4d8e-9f14-c79ac9d8bcda' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-cd8d403a-b45c-4d8e-9f14-c79ac9d8bcda' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-865a1b4c-e92a-456e-a483-8141e358eec5' class='xr-var-data-in' type='checkbox'><label for='data-865a1b4c-e92a-456e-a483-8141e358eec5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 21.25 kiB </td>\n",
       "                        <td> 1.33 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (64, 85) </td>\n",
       "                        <td> (4, 85) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 16 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> int32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"140\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"5\" x2=\"120\" y2=\"5\" />\n",
       "  <line x1=\"0\" y1=\"11\" x2=\"120\" y2=\"11\" />\n",
       "  <line x1=\"0\" y1=\"16\" x2=\"120\" y2=\"16\" />\n",
       "  <line x1=\"0\" y1=\"22\" x2=\"120\" y2=\"22\" />\n",
       "  <line x1=\"0\" y1=\"28\" x2=\"120\" y2=\"28\" />\n",
       "  <line x1=\"0\" y1=\"33\" x2=\"120\" y2=\"33\" />\n",
       "  <line x1=\"0\" y1=\"39\" x2=\"120\" y2=\"39\" />\n",
       "  <line x1=\"0\" y1=\"45\" x2=\"120\" y2=\"45\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"120\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"120\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"62\" x2=\"120\" y2=\"62\" />\n",
       "  <line x1=\"0\" y1=\"67\" x2=\"120\" y2=\"67\" />\n",
       "  <line x1=\"0\" y1=\"73\" x2=\"120\" y2=\"73\" />\n",
       "  <line x1=\"0\" y1=\"79\" x2=\"120\" y2=\"79\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"120\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"90\" x2=\"120\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,90.3529411764706 0.0,90.3529411764706\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"110.352941\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >85</text>\n",
       "  <text x=\"140.000000\" y=\"45.176471\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,45.176471)\">64</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>area</span></div><div class='xr-var-dims'>(time, ID)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(4, 85), meta=np.ndarray&gt;</div><input id='attrs-3ecd2f89-3e48-4fd9-b019-031a90bbe464' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3ecd2f89-3e48-4fd9-b019-031a90bbe464' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ad17dece-3e52-40ef-9853-b9e5abd07118' class='xr-var-data-in' type='checkbox'><label for='data-ad17dece-3e52-40ef-9853-b9e5abd07118' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 21.25 kiB </td>\n",
       "                        <td> 1.33 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (64, 85) </td>\n",
       "                        <td> (4, 85) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 16 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"140\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"5\" x2=\"120\" y2=\"5\" />\n",
       "  <line x1=\"0\" y1=\"11\" x2=\"120\" y2=\"11\" />\n",
       "  <line x1=\"0\" y1=\"16\" x2=\"120\" y2=\"16\" />\n",
       "  <line x1=\"0\" y1=\"22\" x2=\"120\" y2=\"22\" />\n",
       "  <line x1=\"0\" y1=\"28\" x2=\"120\" y2=\"28\" />\n",
       "  <line x1=\"0\" y1=\"33\" x2=\"120\" y2=\"33\" />\n",
       "  <line x1=\"0\" y1=\"39\" x2=\"120\" y2=\"39\" />\n",
       "  <line x1=\"0\" y1=\"45\" x2=\"120\" y2=\"45\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"120\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"120\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"62\" x2=\"120\" y2=\"62\" />\n",
       "  <line x1=\"0\" y1=\"67\" x2=\"120\" y2=\"67\" />\n",
       "  <line x1=\"0\" y1=\"73\" x2=\"120\" y2=\"73\" />\n",
       "  <line x1=\"0\" y1=\"79\" x2=\"120\" y2=\"79\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"120\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"90\" x2=\"120\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,90.3529411764706 0.0,90.3529411764706\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"110.352941\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >85</text>\n",
       "  <text x=\"140.000000\" y=\"45.176471\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,45.176471)\">64</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>centroid</span></div><div class='xr-var-dims'>(component, time, ID)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(2, 4, 85), meta=np.ndarray&gt;</div><input id='attrs-3f5df033-6c42-470e-a399-3ff5bfd7c14a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3f5df033-6c42-470e-a399-3ff5bfd7c14a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0db3d9f7-05d1-49cc-b03d-497dd50e4a27' class='xr-var-data-in' type='checkbox'><label for='data-0db3d9f7-05d1-49cc-b03d-497dd50e4a27' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 42.50 kiB </td>\n",
       "                        <td> 2.66 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (2, 64, 85) </td>\n",
       "                        <td> (2, 4, 85) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 16 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"197\" height=\"157\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"27\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"5\" x2=\"27\" y2=\"23\" />\n",
       "  <line x1=\"10\" y1=\"11\" x2=\"27\" y2=\"28\" />\n",
       "  <line x1=\"10\" y1=\"16\" x2=\"27\" y2=\"34\" />\n",
       "  <line x1=\"10\" y1=\"22\" x2=\"27\" y2=\"40\" />\n",
       "  <line x1=\"10\" y1=\"28\" x2=\"27\" y2=\"45\" />\n",
       "  <line x1=\"10\" y1=\"33\" x2=\"27\" y2=\"51\" />\n",
       "  <line x1=\"10\" y1=\"39\" x2=\"27\" y2=\"57\" />\n",
       "  <line x1=\"10\" y1=\"45\" x2=\"27\" y2=\"62\" />\n",
       "  <line x1=\"10\" y1=\"50\" x2=\"27\" y2=\"68\" />\n",
       "  <line x1=\"10\" y1=\"56\" x2=\"27\" y2=\"74\" />\n",
       "  <line x1=\"10\" y1=\"62\" x2=\"27\" y2=\"79\" />\n",
       "  <line x1=\"10\" y1=\"67\" x2=\"27\" y2=\"85\" />\n",
       "  <line x1=\"10\" y1=\"73\" x2=\"27\" y2=\"91\" />\n",
       "  <line x1=\"10\" y1=\"79\" x2=\"27\" y2=\"96\" />\n",
       "  <line x1=\"10\" y1=\"84\" x2=\"27\" y2=\"102\" />\n",
       "  <line x1=\"10\" y1=\"90\" x2=\"27\" y2=\"107\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"107\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 27.622768707106896,17.622768707106896 27.622768707106896,107.9757098835775 10.0,90.3529411764706\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"147\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"27\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"147\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 147.6227687071069,17.622768707106896 27.622768707106896,17.622768707106896\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"147\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"27\" y1=\"23\" x2=\"147\" y2=\"23\" />\n",
       "  <line x1=\"27\" y1=\"28\" x2=\"147\" y2=\"28\" />\n",
       "  <line x1=\"27\" y1=\"34\" x2=\"147\" y2=\"34\" />\n",
       "  <line x1=\"27\" y1=\"40\" x2=\"147\" y2=\"40\" />\n",
       "  <line x1=\"27\" y1=\"45\" x2=\"147\" y2=\"45\" />\n",
       "  <line x1=\"27\" y1=\"51\" x2=\"147\" y2=\"51\" />\n",
       "  <line x1=\"27\" y1=\"57\" x2=\"147\" y2=\"57\" />\n",
       "  <line x1=\"27\" y1=\"62\" x2=\"147\" y2=\"62\" />\n",
       "  <line x1=\"27\" y1=\"68\" x2=\"147\" y2=\"68\" />\n",
       "  <line x1=\"27\" y1=\"74\" x2=\"147\" y2=\"74\" />\n",
       "  <line x1=\"27\" y1=\"79\" x2=\"147\" y2=\"79\" />\n",
       "  <line x1=\"27\" y1=\"85\" x2=\"147\" y2=\"85\" />\n",
       "  <line x1=\"27\" y1=\"91\" x2=\"147\" y2=\"91\" />\n",
       "  <line x1=\"27\" y1=\"96\" x2=\"147\" y2=\"96\" />\n",
       "  <line x1=\"27\" y1=\"102\" x2=\"147\" y2=\"102\" />\n",
       "  <line x1=\"27\" y1=\"107\" x2=\"147\" y2=\"107\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"107\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"147\" y1=\"17\" x2=\"147\" y2=\"107\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"27.622768707106896,17.622768707106896 147.6227687071069,17.622768707106896 147.6227687071069,107.9757098835775 27.622768707106896,107.9757098835775\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"87.622769\" y=\"127.975710\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >85</text>\n",
       "  <text x=\"167.622769\" y=\"62.799239\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,167.622769,62.799239)\">64</text>\n",
       "  <text x=\"8.811384\" y=\"119.164326\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.811384,119.164326)\">2</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>presence</span></div><div class='xr-var-dims'>(time, ID)</div><div class='xr-var-dtype'>bool</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(4, 85), meta=np.ndarray&gt;</div><input id='attrs-a3503f66-7085-4dbc-bd61-41a9546be4f7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a3503f66-7085-4dbc-bd61-41a9546be4f7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-cbcfa9e1-d7b4-4f87-a2ea-b6a03e4e2266' class='xr-var-data-in' type='checkbox'><label for='data-cbcfa9e1-d7b4-4f87-a2ea-b6a03e4e2266' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 5.31 kiB </td>\n",
       "                        <td> 340 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (64, 85) </td>\n",
       "                        <td> (4, 85) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 16 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> bool numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"140\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"5\" x2=\"120\" y2=\"5\" />\n",
       "  <line x1=\"0\" y1=\"11\" x2=\"120\" y2=\"11\" />\n",
       "  <line x1=\"0\" y1=\"16\" x2=\"120\" y2=\"16\" />\n",
       "  <line x1=\"0\" y1=\"22\" x2=\"120\" y2=\"22\" />\n",
       "  <line x1=\"0\" y1=\"28\" x2=\"120\" y2=\"28\" />\n",
       "  <line x1=\"0\" y1=\"33\" x2=\"120\" y2=\"33\" />\n",
       "  <line x1=\"0\" y1=\"39\" x2=\"120\" y2=\"39\" />\n",
       "  <line x1=\"0\" y1=\"45\" x2=\"120\" y2=\"45\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"120\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"120\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"62\" x2=\"120\" y2=\"62\" />\n",
       "  <line x1=\"0\" y1=\"67\" x2=\"120\" y2=\"67\" />\n",
       "  <line x1=\"0\" y1=\"73\" x2=\"120\" y2=\"73\" />\n",
       "  <line x1=\"0\" y1=\"79\" x2=\"120\" y2=\"79\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"120\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"90\" x2=\"120\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"90\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,90.3529411764706 0.0,90.3529411764706\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"110.352941\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >85</text>\n",
       "  <text x=\"140.000000\" y=\"45.176471\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,45.176471)\">64</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>time_start</span></div><div class='xr-var-dims'>(ID)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(85,), meta=np.ndarray&gt;</div><input id='attrs-9dbadcac-cbdf-498f-b76b-e26d56692803' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9dbadcac-cbdf-498f-b76b-e26d56692803' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-82c8f1c0-2538-4639-bdc8-7a9e194634bd' class='xr-var-data-in' type='checkbox'><label for='data-82c8f1c0-2538-4639-bdc8-7a9e194634bd' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 680 B </td>\n",
       "                        <td> 680 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (85,) </td>\n",
       "                        <td> (85,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> datetime64[ns] numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"76\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"26\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,26.207589997831487 0.0,26.207589997831487\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"46.207590\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >85</text>\n",
       "  <text x=\"140.000000\" y=\"13.103795\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,13.103795)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>time_end</span></div><div class='xr-var-dims'>(ID)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(85,), meta=np.ndarray&gt;</div><input id='attrs-423ac61a-76d4-4176-b73d-64a553521ec0' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-423ac61a-76d4-4176-b73d-64a553521ec0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-26aff648-7af1-4885-9b0b-d8ab20cca1a0' class='xr-var-data-in' type='checkbox'><label for='data-26aff648-7af1-4885-9b0b-d8ab20cca1a0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 680 B </td>\n",
       "                        <td> 680 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (85,) </td>\n",
       "                        <td> (85,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> datetime64[ns] numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"76\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"26\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,26.207589997831487 0.0,26.207589997831487\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"46.207590\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >85</text>\n",
       "  <text x=\"140.000000\" y=\"13.103795\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,13.103795)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>merge_ledger</span></div><div class='xr-var-dims'>(time, ID, sibling_ID)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(4, 85, 3), meta=np.ndarray&gt;</div><input id='attrs-a4a502e4-e458-4b35-8e09-ff77d494816a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a4a502e4-e458-4b35-8e09-ff77d494816a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8f87b6c9-9d98-464e-941d-e1da1714ac9b' class='xr-var-data-in' type='checkbox'><label for='data-8f87b6c9-9d98-464e-941d-e1da1714ac9b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 63.75 kiB </td>\n",
       "                        <td> 3.98 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (64, 85, 3) </td>\n",
       "                        <td> (4, 85, 3) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 16 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> int32 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"145\" height=\"223\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"63\" y2=\"53\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"63\" y2=\"173\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"123\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"126\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"19\" y2=\"129\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"133\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" />\n",
       "  <line x1=\"29\" y1=\"19\" x2=\"29\" y2=\"139\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"33\" y2=\"143\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"36\" y2=\"146\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"149\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"43\" y2=\"153\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"156\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"159\" />\n",
       "  <line x1=\"53\" y1=\"43\" x2=\"53\" y2=\"163\" />\n",
       "  <line x1=\"56\" y1=\"46\" x2=\"56\" y2=\"166\" />\n",
       "  <line x1=\"59\" y1=\"49\" x2=\"59\" y2=\"169\" />\n",
       "  <line x1=\"63\" y1=\"53\" x2=\"63\" y2=\"173\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 63.148788927335644,53.148788927335644 63.148788927335644,173.14878892733566 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"42\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"45\" y2=\"3\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"49\" y2=\"6\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"52\" y2=\"9\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"55\" y2=\"13\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"58\" y2=\"16\" />\n",
       "  <line x1=\"29\" y1=\"19\" x2=\"62\" y2=\"19\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"65\" y2=\"23\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"68\" y2=\"26\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"72\" y2=\"29\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"75\" y2=\"33\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"78\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"82\" y2=\"39\" />\n",
       "  <line x1=\"53\" y1=\"43\" x2=\"85\" y2=\"43\" />\n",
       "  <line x1=\"56\" y1=\"46\" x2=\"88\" y2=\"46\" />\n",
       "  <line x1=\"59\" y1=\"49\" x2=\"92\" y2=\"49\" />\n",
       "  <line x1=\"63\" y1=\"53\" x2=\"95\" y2=\"53\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"63\" y2=\"53\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"42\" y1=\"0\" x2=\"95\" y2=\"53\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 42.37078133389812,0.0 95.51957026123377,53.148788927335644 63.148788927335644,53.148788927335644\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"63\" y1=\"53\" x2=\"95\" y2=\"53\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"63\" y1=\"173\" x2=\"95\" y2=\"173\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"63\" y1=\"53\" x2=\"63\" y2=\"173\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"95\" y1=\"53\" x2=\"95\" y2=\"173\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"63.148788927335644,53.148788927335644 95.51957026123377,53.148788927335644 95.51957026123377,173.14878892733566 63.148788927335644,173.14878892733566\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"79.334180\" y=\"193.148789\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"115.519570\" y=\"113.148789\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,115.519570,113.148789)\">85</text>\n",
       "  <text x=\"26.574394\" y=\"166.574394\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,26.574394,166.574394)\">64</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(ncells)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(14886338,), meta=np.ndarray&gt;</div><input id='attrs-2dd75b56-d188-4fc7-a08b-dc1bf4a5d4fd' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2dd75b56-d188-4fc7-a08b-dc1bf4a5d4fd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d54b4066-43f5-49fe-a98c-a3b90ffd331d' class='xr-var-data-in' type='checkbox'><label for='data-d54b4066-43f5-49fe-a98c-a3b90ffd331d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>bounds :</span></dt><dd>clat_vertices</dd><dt><span>long_name :</span></dt><dd>center latitude</dd><dt><span>standard_name :</span></dt><dd>grid_latitude</dd><dt><span>units :</span></dt><dd>degrees</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 113.57 MiB </td>\n",
       "                        <td> 113.57 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (14886338,) </td>\n",
       "                        <td> (14886338,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >14886338</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(ncells)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(14886338,), meta=np.ndarray&gt;</div><input id='attrs-2ea75f2c-797e-461a-83e7-f8fb3d14571d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2ea75f2c-797e-461a-83e7-f8fb3d14571d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7142eef1-a259-4ee9-a50f-900bcd0482eb' class='xr-var-data-in' type='checkbox'><label for='data-7142eef1-a259-4ee9-a50f-900bcd0482eb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>bounds :</span></dt><dd>clon_vertices</dd><dt><span>long_name :</span></dt><dd>center longitude</dd><dt><span>standard_name :</span></dt><dd>grid_longitude</dd><dt><span>units :</span></dt><dd>degrees</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 113.57 MiB </td>\n",
       "                        <td> 113.57 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (14886338,) </td>\n",
       "                        <td> (14886338,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >14886338</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-2b4b2272-1f17-4054-9646-7f4460625741' class='xr-section-summary-in' type='checkbox'  ><label for='section-2b4b2272-1f17-4054-9646-7f4460625741' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-4b820bd8-c524-4cff-8e7c-83ce0cc65c38' class='xr-index-data-in' type='checkbox'/><label for='index-4b820bd8-c524-4cff-8e7c-83ce0cc65c38' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2002-04-11 23:59:00&#x27;, &#x27;2002-04-12 23:59:00&#x27;,\n",
       "               &#x27;2002-04-13 23:59:00&#x27;, &#x27;2002-04-14 23:59:00&#x27;,\n",
       "               &#x27;2002-04-15 23:59:00&#x27;, &#x27;2002-04-16 23:59:00&#x27;,\n",
       "               &#x27;2002-04-17 23:59:00&#x27;, &#x27;2002-04-18 23:59:00&#x27;,\n",
       "               &#x27;2002-04-19 23:59:00&#x27;, &#x27;2002-04-20 23:59:00&#x27;,\n",
       "               &#x27;2002-04-21 23:59:00&#x27;, &#x27;2002-04-22 23:59:00&#x27;,\n",
       "               &#x27;2002-04-23 23:59:00&#x27;, &#x27;2002-04-24 23:59:00&#x27;,\n",
       "               &#x27;2002-04-25 23:59:00&#x27;, &#x27;2002-04-26 23:59:00&#x27;,\n",
       "               &#x27;2002-04-27 23:59:00&#x27;, &#x27;2002-04-28 23:59:00&#x27;,\n",
       "               &#x27;2002-04-29 23:59:00&#x27;, &#x27;2002-04-30 23:59:00&#x27;,\n",
       "               &#x27;2002-05-01 23:59:00&#x27;, &#x27;2002-05-02 23:59:00&#x27;,\n",
       "               &#x27;2002-05-03 23:59:00&#x27;, &#x27;2002-05-04 23:59:00&#x27;,\n",
       "               &#x27;2002-05-05 23:59:00&#x27;, &#x27;2002-05-06 23:59:00&#x27;,\n",
       "               &#x27;2002-05-07 23:59:00&#x27;, &#x27;2002-05-08 23:59:00&#x27;,\n",
       "               &#x27;2002-05-09 23:59:00&#x27;, &#x27;2002-05-10 23:59:00&#x27;,\n",
       "               &#x27;2002-05-11 23:59:00&#x27;, &#x27;2002-05-12 23:59:00&#x27;,\n",
       "               &#x27;2002-05-13 23:59:00&#x27;, &#x27;2002-05-14 23:59:00&#x27;,\n",
       "               &#x27;2002-05-15 23:59:00&#x27;, &#x27;2002-05-16 23:59:00&#x27;,\n",
       "               &#x27;2002-05-17 23:59:00&#x27;, &#x27;2002-05-18 23:59:00&#x27;,\n",
       "               &#x27;2002-05-19 23:59:00&#x27;, &#x27;2002-05-20 23:59:00&#x27;,\n",
       "               &#x27;2002-05-21 23:59:00&#x27;, &#x27;2002-05-22 23:59:00&#x27;,\n",
       "               &#x27;2002-05-23 23:59:00&#x27;, &#x27;2002-05-24 23:59:00&#x27;,\n",
       "               &#x27;2002-05-25 23:59:00&#x27;, &#x27;2002-05-26 23:59:00&#x27;,\n",
       "               &#x27;2002-05-27 23:59:00&#x27;, &#x27;2002-05-28 23:59:00&#x27;,\n",
       "               &#x27;2002-05-29 23:59:00&#x27;, &#x27;2002-05-30 23:59:00&#x27;,\n",
       "               &#x27;2002-05-31 23:59:00&#x27;, &#x27;2002-06-01 23:59:00&#x27;,\n",
       "               &#x27;2002-06-02 23:59:00&#x27;, &#x27;2002-06-03 23:59:00&#x27;,\n",
       "               &#x27;2002-06-04 23:59:00&#x27;, &#x27;2002-06-05 23:59:00&#x27;,\n",
       "               &#x27;2002-06-06 23:59:00&#x27;, &#x27;2002-06-07 23:59:00&#x27;,\n",
       "               &#x27;2002-06-08 23:59:00&#x27;, &#x27;2002-06-09 23:59:00&#x27;,\n",
       "               &#x27;2002-06-10 23:59:00&#x27;, &#x27;2002-06-11 23:59:00&#x27;,\n",
       "               &#x27;2002-06-12 23:59:00&#x27;, &#x27;2002-06-13 23:59:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>ID</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-51e47ce7-8426-4702-b081-ff4b6b42f923' class='xr-index-data-in' type='checkbox'/><label for='index-51e47ce7-8426-4702-b081-ff4b6b42f923' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "       55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85],\n",
       "      dtype=&#x27;int32&#x27;, name=&#x27;ID&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-08e89c8a-ef85-4689-ad06-ddba6f0c6293' class='xr-section-summary-in' type='checkbox'  ><label for='section-08e89c8a-ef85-4689-ad06-ddba6f0c6293' class='xr-section-summary' >Attributes: <span>(13)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>allow_merging :</span></dt><dd>1</dd><dt><span>N_blobs_prefiltered :</span></dt><dd>3405</dd><dt><span>N_blobs_final :</span></dt><dd>84</dd><dt><span>R_fill :</span></dt><dd>32</dd><dt><span>T_fill :</span></dt><dd>2</dd><dt><span>area_filter_quartile :</span></dt><dd>0.8</dd><dt><span>area_threshold (cells) :</span></dt><dd>19152.000000000004</dd><dt><span>accepted_area_fraction :</span></dt><dd>0.7985329049105939</dd><dt><span>preprocessed_area_fraction :</span></dt><dd>0.7691209876330218</dd><dt><span>overlap_threshold :</span></dt><dd>0.5</dd><dt><span>nn_partitioning :</span></dt><dd>1</dd><dt><span>total_merges :</span></dt><dd>38</dd><dt><span>multi_parent_merges :</span></dt><dd>3</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 4GB\n",
       "Dimensions:       (time: 64, ncells: 14886338, ID: 85, component: 2,\n",
       "                   sibling_ID: 3)\n",
       "Coordinates:\n",
       "  * time          (time) datetime64[ns] 512B 2002-04-11T23:59:00 ... 2002-06-...\n",
       "  * ID            (ID) int32 340B 1 2 3 4 5 6 7 8 9 ... 78 79 80 81 82 83 84 85\n",
       "Dimensions without coordinates: ncells, component, sibling_ID\n",
       "Data variables:\n",
       "    ID_field      (time, ncells) int32 4GB dask.array<chunksize=(4, 14886338), meta=np.ndarray>\n",
       "    global_ID     (time, ID) int32 22kB dask.array<chunksize=(4, 85), meta=np.ndarray>\n",
       "    area          (time, ID) float32 22kB dask.array<chunksize=(4, 85), meta=np.ndarray>\n",
       "    centroid      (component, time, ID) float32 44kB dask.array<chunksize=(2, 4, 85), meta=np.ndarray>\n",
       "    presence      (time, ID) bool 5kB dask.array<chunksize=(4, 85), meta=np.ndarray>\n",
       "    time_start    (ID) datetime64[ns] 680B dask.array<chunksize=(85,), meta=np.ndarray>\n",
       "    time_end      (ID) datetime64[ns] 680B dask.array<chunksize=(85,), meta=np.ndarray>\n",
       "    merge_ledger  (time, ID, sibling_ID) int32 65kB dask.array<chunksize=(4, 85, 3), meta=np.ndarray>\n",
       "    lat           (ncells) float64 119MB dask.array<chunksize=(14886338,), meta=np.ndarray>\n",
       "    lon           (ncells) float64 119MB dask.array<chunksize=(14886338,), meta=np.ndarray>\n",
       "Attributes: (12/13)\n",
       "    allow_merging:               1\n",
       "    N_blobs_prefiltered:         3405\n",
       "    N_blobs_final:               84\n",
       "    R_fill:                      32\n",
       "    T_fill:                      2\n",
       "    area_filter_quartile:        0.8\n",
       "    ...                          ...\n",
       "    accepted_area_fraction:      0.7985329049105939\n",
       "    preprocessed_area_fraction:  0.7691209876330218\n",
       "    overlap_threshold:           0.5\n",
       "    nn_partitioning:             1\n",
       "    total_merges:                38\n",
       "    multi_parent_merges:         3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SpOt & Track the Blobs & Merger Events\n",
    "\n",
    "tracker = blob.Spotter(ds.extreme_events, ds.mask, R_fill=hole_filling_radius, T_fill = time_gap_fill, area_filter_quartile=drop_area_quartile, \n",
    "                       allow_merging=allow_merging, overlap_threshold=overlap_threshold, nn_partitioning=nn_partitioning, \n",
    "                       temp_dir='/scratch/b/b382615/mhws/TEMP/', # Temporary Scratch Directory for Dask\n",
    "                       xdim='ncells',                 # Need to tell spot_the_blOb the new Unstructured dimension\n",
    "                       unstructured_grid=True,        # Use Unstructured Grid\n",
    "                       neighbours=ds.neighbours,      # Connectivity array for the Unstructured Grid Cells\n",
    "                       cell_areas=ds.cell_areas,      # Cell areas for each Unstructured Grid Cell\n",
    "                       verbosity=2)                   # Choose Verbosity Level (0=None, 1=Basic, 2=Advanced/Timing)\n",
    "\n",
    "blobs = tracker.run(return_merges=False)\n",
    "\n",
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e1a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c222c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e67fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bfe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from dask.distributed import wait\n",
    "from dask_image.ndmeasure import label\n",
    "from skimage.measure import regionprops_table\n",
    "from dask_image.ndmorph import binary_closing as binary_closing_dask\n",
    "from dask_image.ndmorph import binary_opening as binary_opening_dask\n",
    "from scipy.ndimage import binary_closing, binary_opening\n",
    "from scipy.sparse import coo_matrix, csr_matrix, eye\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from dask import persist\n",
    "from dask import delayed\n",
    "from dask import compute as dask_compute\n",
    "import dask.array as dsa\n",
    "from dask.base import is_dask_collection\n",
    "from numba import jit, njit, prange\n",
    "import jax.numpy as jnp\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import logging\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##################################\n",
    "### Optimised Helper Functions ###\n",
    "##################################\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True, fastmath=True)\n",
    "def wrapped_euclidian_parallel(mask_values, parent_centroids_values, Nx):\n",
    "    \"\"\"\n",
    "    Optimised function for computing wrapped Euclidean distances.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mask_values : np.ndarray\n",
    "        2D boolean array where True indicates points to calculate distances for\n",
    "    parent_centroids_values : np.ndarray\n",
    "        Array of shape (n_parents, 2) containing (y, x) coordinates of parent centroids\n",
    "    Nx : int\n",
    "        Size of the x-dimension for wrapping\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    distances : np.ndarray\n",
    "        Array of shape (n_true_points, n_parents) with minimum distances\n",
    "    \"\"\"\n",
    "    n_parents = len(parent_centroids_values)\n",
    "    half_Nx = Nx / 2\n",
    "    \n",
    "    y_indices, x_indices = np.nonzero(mask_values)\n",
    "    n_true = len(y_indices)\n",
    "    \n",
    "    distances = np.empty((n_true, n_parents), dtype=np.float64)\n",
    "    \n",
    "    # Precompute for faster access\n",
    "    parent_y = parent_centroids_values[:, 0]\n",
    "    parent_x = parent_centroids_values[:, 1]\n",
    "    \n",
    "    # Parallel loop over true positions\n",
    "    for idx in prange(n_true):\n",
    "        y, x = y_indices[idx], x_indices[idx]\n",
    "        \n",
    "        # Pre-compute y differences for all parents\n",
    "        dy = y - parent_y\n",
    "        \n",
    "        # Pre-compute x differences for all parents\n",
    "        dx = x - parent_x\n",
    "        \n",
    "        # Wrapping correction\n",
    "        dx = np.where(dx > half_Nx, dx - Nx, dx)\n",
    "        dx = np.where(dx < -half_Nx, dx + Nx, dx)\n",
    "        \n",
    "        distances[idx] = np.sqrt(dy * dy + dx * dx)\n",
    "    \n",
    "    return distances\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True, fastmath=True)\n",
    "def create_grid_index_arrays(points_y, points_x, grid_size, ny, nx):\n",
    "    \"\"\"\n",
    "    Creates a grid-based spatial index using numpy arrays.\n",
    "    \"\"\"\n",
    "    n_grids_y = (ny + grid_size - 1) // grid_size\n",
    "    n_grids_x = (nx + grid_size - 1) // grid_size\n",
    "    max_points_per_cell = len(points_y)\n",
    "    \n",
    "    grid_points = np.full((n_grids_y, n_grids_x, max_points_per_cell), -1, dtype=np.int32)\n",
    "    grid_counts = np.zeros((n_grids_y, n_grids_x), dtype=np.int32)\n",
    "    \n",
    "    for idx in range(len(points_y)):\n",
    "        grid_y = min(points_y[idx] // grid_size, n_grids_y - 1)\n",
    "        grid_x = min(points_x[idx] // grid_size, n_grids_x - 1)\n",
    "        count = grid_counts[grid_y, grid_x]\n",
    "        if count < max_points_per_cell:\n",
    "            grid_points[grid_y, grid_x, count] = idx\n",
    "            grid_counts[grid_y, grid_x] += 1\n",
    "    \n",
    "    return grid_points, grid_counts\n",
    "\n",
    "@jit(nopython=True, fastmath=True)\n",
    "def calculate_wrapped_distance(y1, x1, y2, x2, nx, half_nx):\n",
    "    \"\"\"\n",
    "    Calculate distance with periodic boundary conditions in x dimension.\n",
    "    \"\"\"\n",
    "    dy = y1 - y2\n",
    "    dx = x1 - x2\n",
    "    \n",
    "    if dx > half_nx:\n",
    "        dx -= nx\n",
    "    elif dx < -half_nx:\n",
    "        dx += nx\n",
    "        \n",
    "    return np.sqrt(dy * dy + dx * dx)\n",
    "\n",
    "@jit(nopython=True, parallel=True, fastmath=True)\n",
    "def partition_nn_grid(child_mask, parent_masks, child_ids, parent_centroids, Nx, max_distance=20):\n",
    "    \"\"\"\n",
    "    Assigns labels based on nearest parent blob points.\n",
    "    This is quite computationally-intensive, so we utilise many optimisations here...\n",
    "    \"\"\"\n",
    "    \n",
    "    ny, nx = child_mask.shape\n",
    "    half_Nx = Nx / 2\n",
    "    n_parents = len(parent_masks)\n",
    "    grid_size = max(2, max_distance // 4)\n",
    "    \n",
    "    y_indices, x_indices = np.nonzero(child_mask)\n",
    "    n_child_points = len(y_indices)\n",
    "    \n",
    "    min_distances = np.full(n_child_points, np.inf)\n",
    "    parent_assignments = np.zeros(n_child_points, dtype=np.int32)\n",
    "    found_close = np.zeros(n_child_points, dtype=np.bool_)\n",
    "    \n",
    "    for parent_idx in range(n_parents):\n",
    "        py, px = np.nonzero(parent_masks[parent_idx])\n",
    "        \n",
    "        if len(py) == 0:  # Skip empty parents\n",
    "            continue\n",
    "            \n",
    "        # Create grid index for this parent\n",
    "        n_grids_y = (ny + grid_size - 1) // grid_size\n",
    "        n_grids_x = (nx + grid_size - 1) // grid_size\n",
    "        grid_points, grid_counts = create_grid_index_arrays(py, px, grid_size, ny, nx)\n",
    "        \n",
    "        # Process child points in parallel\n",
    "        for child_idx in prange(n_child_points):\n",
    "            if found_close[child_idx]:  # Skip if we already found an exact match\n",
    "                continue\n",
    "                \n",
    "            child_y, child_x = y_indices[child_idx], x_indices[child_idx]\n",
    "            grid_y = min(child_y // grid_size, n_grids_y - 1)\n",
    "            grid_x = min(child_x // grid_size, n_grids_x - 1)\n",
    "            \n",
    "            min_dist_to_parent = np.inf\n",
    "            \n",
    "            # Check nearby grid cells\n",
    "            for dy in range(-1, 2):\n",
    "                grid_y_check = (grid_y + dy) % n_grids_y\n",
    "                \n",
    "                for dx in range(-1, 2):\n",
    "                    grid_x_check = (grid_x + dx) % n_grids_x\n",
    "                    \n",
    "                    # Process points in this grid cell\n",
    "                    n_points = grid_counts[grid_y_check, grid_x_check]\n",
    "                    \n",
    "                    for p_idx in range(n_points):\n",
    "                        point_idx = grid_points[grid_y_check, grid_x_check, p_idx]\n",
    "                        if point_idx == -1:\n",
    "                            break\n",
    "                        \n",
    "                        dist = calculate_wrapped_distance(\n",
    "                            child_y, child_x,\n",
    "                            py[point_idx], px[point_idx],\n",
    "                            Nx, half_Nx\n",
    "                        )\n",
    "                        \n",
    "                        if dist > max_distance:\n",
    "                            continue\n",
    "                        \n",
    "                        if dist < min_dist_to_parent:\n",
    "                            min_dist_to_parent = dist\n",
    "                            \n",
    "                        if dist < 1e-6:  # Found exact same point (within numerical precision)\n",
    "                            min_dist_to_parent = dist\n",
    "                            found_close[child_idx] = True\n",
    "                            break\n",
    "                    \n",
    "                    if found_close[child_idx]:\n",
    "                        break\n",
    "                \n",
    "                if found_close[child_idx]:\n",
    "                    break\n",
    "            \n",
    "            # Update assignment if this parent is closer\n",
    "            if min_dist_to_parent < min_distances[child_idx]:\n",
    "                min_distances[child_idx] = min_dist_to_parent\n",
    "                parent_assignments[child_idx] = parent_idx\n",
    "    \n",
    "    # Handle any unassigned points using centroids\n",
    "    unassigned = min_distances == np.inf\n",
    "    if np.any(unassigned):\n",
    "        for child_idx in np.nonzero(unassigned)[0]:\n",
    "            child_y, child_x = y_indices[child_idx], x_indices[child_idx]\n",
    "            min_dist = np.inf\n",
    "            best_parent = 0\n",
    "            \n",
    "            for parent_idx in range(n_parents):\n",
    "                # Calculate distance to centroid with periodic boundary conditions\n",
    "                dist = calculate_wrapped_distance(\n",
    "                    child_y, child_x,\n",
    "                    parent_centroids[parent_idx, 0],\n",
    "                    parent_centroids[parent_idx, 1],\n",
    "                    Nx, half_Nx\n",
    "                )\n",
    "                \n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    best_parent = parent_idx\n",
    "                    \n",
    "            parent_assignments[child_idx] = best_parent\n",
    "    \n",
    "    # Convert from parent indices to child_ids\n",
    "    new_labels = child_ids[parent_assignments]\n",
    "    \n",
    "    return new_labels\n",
    "\n",
    "\n",
    "@jit(nopython=True, fastmath=True)\n",
    "def partition_nn_unstructured(child_mask, parent_masks, child_ids, parent_centroids, neighbours_int, lat, lon, max_distance=20):\n",
    "    \"\"\"\n",
    "    Optimised version of nearest parent label assignment for unstructured grids.\n",
    "    Uses numpy arrays throughout to ensure Numba compatibility.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    child_mask : np.ndarray\n",
    "        1D boolean array where True indicates points in the child blob\n",
    "    parent_masks : np.ndarray\n",
    "        2D boolean array of shape (n_parents, n_points) where True indicates points in each parent blob\n",
    "    child_ids : np.ndarray\n",
    "        1D array containing the IDs to assign to each partition of the child blob\n",
    "    parent_centroids : np.ndarray\n",
    "        Array of shape (n_parents, 2) containing (lat, lon) coordinates of parent centroids in degrees\n",
    "    neighbours_int : np.ndarray\n",
    "        2D array of shape (3, n_points) containing indices of neighboring cells for each point\n",
    "    lat / lon : np.ndarray\n",
    "        Latitude/Longitude in degrees\n",
    "    max_distance : int, optional\n",
    "        Maximum number of edge hops to search for parent points\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    new_labels : np.ndarray\n",
    "        1D array containing the assigned child_ids for each True point in child_mask\n",
    "    \"\"\"\n",
    "    \n",
    "    # Force contiguous arrays in memory for optimal vectorised performance (from indexing)\n",
    "    child_mask = np.ascontiguousarray(child_mask)\n",
    "    parent_masks = np.ascontiguousarray(parent_masks)\n",
    "    \n",
    "    n_points = len(child_mask)\n",
    "    n_parents = len(parent_masks)\n",
    "    \n",
    "    # Pre-allocate arrays\n",
    "    distances = np.full(n_points, np.inf, dtype=np.float32)\n",
    "    parent_assignments = np.full(n_points, -1, dtype=np.int32)\n",
    "    visited = np.zeros((n_parents, n_points), dtype=np.bool_)\n",
    "    \n",
    "    # Initialise with direct overlaps\n",
    "    for parent_idx in range(n_parents):\n",
    "        overlap_mask = parent_masks[parent_idx] & child_mask\n",
    "        if np.any(overlap_mask):\n",
    "            visited[parent_idx, overlap_mask] = True\n",
    "            unclaimed_overlap = distances[overlap_mask] == np.inf\n",
    "            if np.any(unclaimed_overlap):\n",
    "                overlap_points = np.where(overlap_mask)[0]\n",
    "                valid_points = overlap_points[unclaimed_overlap]\n",
    "                distances[valid_points] = 0\n",
    "                parent_assignments[valid_points] = parent_idx\n",
    "    \n",
    "    # Pre-compute trig values\n",
    "    lat_rad = np.deg2rad(lat)\n",
    "    lon_rad = np.deg2rad(lon)\n",
    "    cos_lat = np.cos(lat_rad)\n",
    "    \n",
    "    # Graph traversal for remaining points\n",
    "    current_distance = 0\n",
    "    any_unassigned = np.any(child_mask & (parent_assignments == -1))\n",
    "    \n",
    "    while current_distance < max_distance and any_unassigned:\n",
    "        current_distance += 1\n",
    "        updates_made = False\n",
    "        \n",
    "        for parent_idx in range(n_parents):\n",
    "            # Get current frontier points\n",
    "            frontier_mask = visited[parent_idx]\n",
    "            if not np.any(frontier_mask):\n",
    "                continue\n",
    "            \n",
    "            # Process neighbors\n",
    "            for i in range(3):  # For each neighbor direction\n",
    "                neighbors = neighbours_int[i, frontier_mask]\n",
    "                valid_neighbors = neighbors >= 0\n",
    "                if not np.any(valid_neighbors):\n",
    "                    continue\n",
    "                    \n",
    "                valid_points = neighbors[valid_neighbors]\n",
    "                unvisited = ~visited[parent_idx, valid_points]\n",
    "                new_points = valid_points[unvisited]\n",
    "                \n",
    "                if len(new_points) > 0:\n",
    "                    visited[parent_idx, new_points] = True\n",
    "                    update_mask = distances[new_points] > current_distance\n",
    "                    if np.any(update_mask):\n",
    "                        points_to_update = new_points[update_mask]\n",
    "                        distances[points_to_update] = current_distance\n",
    "                        parent_assignments[points_to_update] = parent_idx\n",
    "                        updates_made = True\n",
    "        \n",
    "        if not updates_made:\n",
    "            break\n",
    "            \n",
    "        any_unassigned = np.any(child_mask & (parent_assignments == -1))\n",
    "    \n",
    "    # Handle remaining unassigned points using great circle distances\n",
    "    unassigned_mask = child_mask & (parent_assignments == -1)\n",
    "    if np.any(unassigned_mask):\n",
    "        parent_lat_rad = np.deg2rad(parent_centroids[:, 0])\n",
    "        parent_lon_rad = np.deg2rad(parent_centroids[:, 1])\n",
    "        cos_parent_lat = np.cos(parent_lat_rad)\n",
    "        \n",
    "        unassigned_points = np.where(unassigned_mask)[0]\n",
    "        for point in unassigned_points:\n",
    "            # Vectorised haversine calculation\n",
    "            dlat = parent_lat_rad - lat_rad[point]\n",
    "            dlon = parent_lon_rad - lon_rad[point]\n",
    "            a = np.sin(dlat/2)**2 + cos_lat[point] * cos_parent_lat * np.sin(dlon/2)**2\n",
    "            dist = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "            parent_assignments[point] = np.argmin(dist)\n",
    "    \n",
    "    # Return only the assignments for points in child_mask\n",
    "    child_points = np.where(child_mask)[0]\n",
    "    return child_ids[parent_assignments[child_points]]\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True, fastmath=True)\n",
    "def partition_nn_unstructured_optimised(child_mask, parent_frontiers, parent_centroids, neighbours_int, lat, lon, max_distance=20):\n",
    "    \"\"\"\n",
    "    Memory-optimised version of nearest parent label assignment for unstructured grids.\n",
    "    Uses numpy arrays throughout to ensure Numba compatibility.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    child_mask : np.ndarray\n",
    "        1D boolean array where True indicates points in the child blob\n",
    "    parent_frontiers : np.ndarray\n",
    "        1D uint8 array with parent indices (255 for unvisited points)\n",
    "    parent_centroids : np.ndarray\n",
    "        Array of shape (n_parents, 2) containing (lat, lon) coordinates\n",
    "    neighbours_int : np.ndarray\n",
    "        2D array of shape (3, n_points) containing indices of neighboring cells\n",
    "    lat / lon : np.ndarray\n",
    "        1D arrays of latitude/longitude in degrees\n",
    "    max_distance : int\n",
    "        Maximum number of edge hops to search for parent points\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result : np.ndarray\n",
    "        1D array containing the assigned parent indices for points in child_mask\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create working copies to ensure memory cleanup\n",
    "    parent_frontiers_working = parent_frontiers.copy()\n",
    "    child_mask_working = child_mask.copy()\n",
    "    \n",
    "    n_parents = np.max(parent_frontiers_working[parent_frontiers_working < 255]) + 1\n",
    "    \n",
    "    # Graph traversal\n",
    "    current_distance = 0\n",
    "    any_unassigned = np.any(child_mask_working & (parent_frontiers_working == 255))\n",
    "    \n",
    "    while current_distance < max_distance and any_unassigned:\n",
    "        current_distance += 1\n",
    "        updates_made = False\n",
    "        \n",
    "        for parent_idx in range(n_parents):\n",
    "            # Skip if no frontier points for this parent\n",
    "            if not np.any(parent_frontiers_working == parent_idx):\n",
    "                continue\n",
    "            \n",
    "            # Process neighbours for current parent's frontier\n",
    "            for i in range(3):\n",
    "                neighbors = neighbours_int[i, parent_frontiers_working == parent_idx]\n",
    "                valid_neighbors = neighbors >= 0\n",
    "                \n",
    "                if not np.any(valid_neighbors):\n",
    "                    continue\n",
    "                \n",
    "                valid_points = neighbors[valid_neighbors]\n",
    "                unvisited = parent_frontiers_working[valid_points] == 255\n",
    "                \n",
    "                if not np.any(unvisited):\n",
    "                    continue\n",
    "                \n",
    "                # Update new frontier points\n",
    "                new_points = valid_points[unvisited]\n",
    "                parent_frontiers_working[new_points] = parent_idx\n",
    "                \n",
    "                if np.any(child_mask_working[new_points]):\n",
    "                    updates_made = True\n",
    "        \n",
    "        if not updates_made:\n",
    "            break\n",
    "            \n",
    "        any_unassigned = np.any(child_mask_working & (parent_frontiers_working == 255))\n",
    "    \n",
    "    # Handle remaining unassigned points using great circle distances\n",
    "    unassigned_mask = child_mask_working & (parent_frontiers_working == 255)\n",
    "    if np.any(unassigned_mask):\n",
    "        # Pre-compute parent coordinates in radians\n",
    "        parent_lat_rad = np.deg2rad(parent_centroids[:, 0])\n",
    "        parent_lon_rad = np.deg2rad(parent_centroids[:, 1])\n",
    "        cos_parent_lat = np.cos(parent_lat_rad)\n",
    "        \n",
    "        # Process each unassigned point\n",
    "        unassigned_points = np.where(unassigned_mask)[0]\n",
    "        for point in unassigned_points:\n",
    "            dlat = parent_lat_rad - np.deg2rad(lat[point])\n",
    "            dlon = parent_lon_rad - np.deg2rad(lon[point])\n",
    "            \n",
    "            a = np.sin(dlat/2)**2 + np.cos(np.deg2rad(lat[point])) * cos_parent_lat * np.sin(dlon/2)**2\n",
    "            dist = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "            \n",
    "            parent_frontiers_working[point] = np.argmin(dist)\n",
    "    \n",
    "    # Extract result for child points only\n",
    "    result = parent_frontiers_working[child_mask_working].copy()\n",
    "    \n",
    "    # Explicitly clear working arrays\n",
    "    parent_frontiers_working = None\n",
    "    child_mask_working = None\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True, fastmath=True)\n",
    "def partition_centroid_unstructured(child_mask, parent_centroids, child_ids, lat, lon):\n",
    "    \"\"\"\n",
    "    Assigns labels to child cells based on closest parent centroid using great circle distances.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    child_mask : np.ndarray\n",
    "        1D boolean array indicating which cells belong to the child blob\n",
    "    parent_centroids : np.ndarray\n",
    "        Array of shape (n_parents, 2) containing (lat, lon) coordinates of parent centroids in degrees\n",
    "    child_ids : np.ndarray\n",
    "        Array of IDs to assign to each partition of the child blob\n",
    "    lat / lon : np.ndarray\n",
    "        Latitude/Longitude in degrees\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    new_labels : np.ndarray\n",
    "        1D array containing assigned child_ids for cells in child_mask\n",
    "    \"\"\"\n",
    "    n_cells = len(child_mask)\n",
    "    n_parents = len(parent_centroids)\n",
    "    \n",
    "    lat_rad = np.deg2rad(lat)\n",
    "    lon_rad = np.deg2rad(lon)\n",
    "    parent_coords_rad = np.deg2rad(parent_centroids)\n",
    "    \n",
    "    new_labels = np.zeros(n_cells, dtype=child_ids.dtype)\n",
    "    \n",
    "    # Process each child cell in parallel\n",
    "    for i in prange(n_cells):\n",
    "        if not child_mask[i]:\n",
    "            continue\n",
    "            \n",
    "        min_dist = np.inf\n",
    "        closest_parent = 0\n",
    "        \n",
    "        # Calculate great circle distance to each parent centroid\n",
    "        for j in range(n_parents):\n",
    "            dlat = parent_coords_rad[j, 0] - lat_rad[i]\n",
    "            dlon = parent_coords_rad[j, 1] - lon_rad[i]\n",
    "            \n",
    "            # Use haversine formula for great circle distance\n",
    "            a = np.sin(dlat/2)**2 + np.cos(lat_rad[i]) * np.cos(parent_coords_rad[j, 0]) * np.sin(dlon/2)**2\n",
    "            dist = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "            \n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_parent = j\n",
    "        \n",
    "        new_labels[i] = child_ids[closest_parent]\n",
    "    \n",
    "    return new_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Helper Function for Super Fast Sparse Bool Multiply (*without the scipy+Dask Memory Leak*)\n",
    "@njit(fastmath=True, parallel=True)\n",
    "def sparse_bool_power(vec, sp_data, indices, indptr, exponent):\n",
    "    vec = vec.T\n",
    "    num_rows = indptr.size - 1\n",
    "    num_cols = vec.shape[1]\n",
    "    result = vec.copy()\n",
    "\n",
    "    for _ in range(exponent):\n",
    "        temp_result = np.zeros((num_rows, num_cols), dtype=np.bool_)\n",
    "\n",
    "        for i in prange(num_rows):\n",
    "            for j in range(indptr[i], indptr[i + 1]):\n",
    "                if sp_data[j]:\n",
    "                    for k in range(num_cols):\n",
    "                        if result[indices[j], k]:\n",
    "                            temp_result[i, k] = True\n",
    "\n",
    "        result = temp_result\n",
    "\n",
    "    return result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Area of Initial Binary Data\n",
    "raw_area = tracker.compute_area(tracker.data_bin)  # This is e.g. the initial Hobday area\n",
    "\n",
    "# Fill Small Holes & Gaps between Objects\n",
    "data_bin_filled = tracker.fill_holes(tracker.data_bin)\n",
    "# Delete the original binary data to free up memory\n",
    "del tracker.data_bin\n",
    "if tracker.verbosity > 0:    print('Finished Filling Spatial Holes')\n",
    "\n",
    "# Fill Small Time-Gaps between Objects\n",
    "data_bin_filled = tracker.fill_time_gaps(data_bin_filled).persist()\n",
    "if tracker.verbosity > 0:    print('Finished Filling Spatio-temporal Holes.')\n",
    "\n",
    "# Remove Small Objects\n",
    "data_bin_filtered, area_threshold, blob_areas, N_blobs_prefiltered = tracker.filter_small_blobs(data_bin_filled)\n",
    "del data_bin_filled\n",
    "if tracker.verbosity > 0:    print('Finished Filtering Small Blobs.')\n",
    "\n",
    "# Clean Up & Persist Preprocessing (This helps avoid block-wise task fusion run_spec issues with dask)\n",
    "data_bin_filtered = data_bin_filtered.persist()\n",
    "wait(data_bin_filtered)\n",
    "        \n",
    "# Compute Area of Morphologically-Processed & Filtered Data\n",
    "processed_area = tracker.compute_area(data_bin_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b567db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bin = data_bin_filtered\n",
    "del data_bin_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster & ID Binary Data at each Time Step\n",
    "blob_id_field, _ = tracker.identify_blobs(data_bin, time_connectivity=False)\n",
    "blob_id_field = blob_id_field.persist()\n",
    "del data_bin\n",
    "if tracker.verbosity > 0:    print('Finished Blob Identification.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ba328",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tracker.unstructured_grid:\n",
    "    # Make the blob_id_field unique across time\n",
    "    cumsum_ids = (blob_id_field.max(dim=tracker.xdim)).cumsum(tracker.timedim).shift({tracker.timedim: 1}, fill_value=0)\n",
    "    blob_id_field = xr.where(blob_id_field > 0, blob_id_field + cumsum_ids, 0)\n",
    "    #blob_id_field = blob_id_field.persist()\n",
    "    if tracker.verbosity > 0:    print('Finished Making Blobs Globally Unique.')\n",
    "\n",
    "# Calculate Properties of each Blob\n",
    "blob_props = tracker.calculate_blob_properties(blob_id_field, properties=['area', 'centroid'])\n",
    "blob_props = blob_props.persist()\n",
    "wait(blob_props)\n",
    "if tracker.verbosity > 0:    print('Finished Calculating Blob Properties.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d098bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id_field_unique = blob_id_field\n",
    "del blob_id_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95218551",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MERGES = 20 # per timestep\n",
    "MAX_PARENTS = 10 # per merge\n",
    "MAX_CHILDREN = MAX_PARENTS\n",
    "        \n",
    "def process_chunk(chunk_data_m1_full, chunk_data_p1_full, merging_blobs, next_id_start, lat, lon, area, neighbours_int):\n",
    "    \"\"\"Process a single chunk of merging blobs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    chunk_data_m1 & chunk_data_p1 : numpy.ndarray\n",
    "        Array of shape (n_time, ncells) for unstructured or (n_time, ny, nx) for structured, shifted by +-1 in time\n",
    "    merging_blobs : numpy.ndarray\n",
    "        Array of shape (n_time, max_merges) containing merging blob IDs (0=none)\n",
    "    next_id_start : numpy.ndarray\n",
    "        Array of shape (n_time, max_merges) containing ID offsets\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing updates for each timestep\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Fix Broadcasted dimensions of inputs: \n",
    "    #    Remove extra dimension if present while preserving time chunks\n",
    "    #    N.B.: This is a weird artefact/choice of xarray apply_ufunc broadcasting... (i.e. 'nv' dimension gets injected into all the other arrays!)\n",
    "    \n",
    "    chunk_data_m1 = chunk_data_m1_full.squeeze()[0].astype(np.int32).copy()\n",
    "    chunk_data    = chunk_data_m1_full.squeeze()[1].astype(np.int32).copy()\n",
    "    del chunk_data_m1_full # Immediately release t+1 data !\n",
    "    chunk_data_p1 = chunk_data_p1_full.squeeze().astype(np.int32).copy()\n",
    "    del chunk_data_p1_full\n",
    "    \n",
    "    lat = lat.squeeze().astype(np.float32)\n",
    "    lon = lon.squeeze().astype(np.float32)\n",
    "    area = area.squeeze().astype(np.float32)\n",
    "    next_id_start = next_id_start.squeeze()\n",
    "    \n",
    "    # Handle neighbours_int with correct dimensions (nv, ncells)\n",
    "    neighbours_int = neighbours_int.squeeze()\n",
    "    if neighbours_int.shape[1] != lat.shape[0]:\n",
    "        neighbours_int = neighbours_int.T\n",
    "    \n",
    "    # Handle multiple merging blobs:\n",
    "    merging_blobs = merging_blobs.squeeze()\n",
    "    if merging_blobs.ndim == 1:\n",
    "        # Add additional (last) dimension for max_merges\n",
    "        merging_blobs = merging_blobs[:, None]\n",
    "    \n",
    "    # Pre-Convert lat/lon to Cartesian\n",
    "    x = (np.cos(np.radians(lat)) * np.cos(np.radians(lon))).astype(np.float32)\n",
    "    y = (np.cos(np.radians(lat)) * np.sin(np.radians(lon))).astype(np.float32)\n",
    "    z = np.sin(np.radians(lat)).astype(np.float32)\n",
    "    \n",
    "    # Pre-allocate arrays for merge events\n",
    "    n_time = chunk_data_p1.shape[0]\n",
    "    n_points = chunk_data_p1.shape[1]\n",
    "    \n",
    "    merge_child_ids = np.full((n_time, MAX_MERGES, MAX_PARENTS), -1, dtype=np.int32)\n",
    "    merge_parent_ids = np.full((n_time, MAX_MERGES, MAX_PARENTS), -1, dtype=np.int32)\n",
    "    merge_areas = np.full((n_time, MAX_MERGES, MAX_PARENTS), -1, dtype=np.float32)\n",
    "    merge_counts = np.zeros(n_time, dtype=np.int16)  # Track number of merges per timestep\n",
    "\n",
    "    updates_array = np.full((n_time, n_points), 255, dtype=np.uint8)\n",
    "    updates_ids   = np.full((n_time, 255), -1, dtype=np.int32)\n",
    "    has_merge = np.zeros(n_time, dtype=np.bool_)\n",
    "    \n",
    "    # Process each timestep\n",
    "    merging_blobs_list = [list(merging_blobs[i][merging_blobs[i]>0]) for i in range(merging_blobs.shape[0])]\n",
    "    final_merging_blobs = np.full((n_time, MAX_MERGES), -1, dtype=np.int32)\n",
    "    final_merge_count = 0\n",
    "    for t in range(n_time):\n",
    "        \n",
    "        next_new_id = next_id_start[t]  # Use the offset for this timestep\n",
    "        \n",
    "        # Get current time slice data\n",
    "        if t == 0:\n",
    "            data_m1 = chunk_data_m1\n",
    "            data_t = chunk_data\n",
    "            del chunk_data_m1, chunk_data\n",
    "        else:\n",
    "            data_m1 = data_t\n",
    "            data_t = data_p1\n",
    "        data_p1 = chunk_data_p1[t]\n",
    "        \n",
    "        \n",
    "        # Process each merging blob at this timestep\n",
    "        while merging_blobs_list[t]:\n",
    "            child_id = merging_blobs_list[t].pop(0)\n",
    "            \n",
    "            # Get child mask and find overlapping parents\n",
    "            child_mask = (data_t == child_id)\n",
    "            \n",
    "            # Find parent blobs that overlap with this child\n",
    "            potential_parents = np.unique(data_m1[child_mask])\n",
    "            parent_iterator = 0\n",
    "            parent_masks_uint = np.full(n_points, 255, dtype=np.uint8)\n",
    "            parent_centroids = np.full((MAX_PARENTS, 2), -1.e10, dtype=np.float32)\n",
    "            parent_ids = np.full(MAX_PARENTS, -1, dtype=np.int32)\n",
    "            parent_areas = np.zeros(MAX_PARENTS, dtype=np.float32)\n",
    "            overlap_areas = np.zeros(MAX_PARENTS, dtype=np.float32)\n",
    "            n_parents = 0\n",
    "            \n",
    "            # Find all unique parent IDs that overlap with the child\n",
    "            for parent_id in potential_parents[potential_parents > 0]:\n",
    "                if n_parents >= MAX_PARENTS:\n",
    "                    raise RuntimeError(f\"Reached maximum number of parents ({MAX_PARENTS}) for child {child_id} at timestep {t}\")\n",
    "                    \n",
    "                parent_mask = (data_m1 == parent_id)\n",
    "                if np.any(parent_mask & child_mask):\n",
    "                    \n",
    "                    # Check if overlap area is large enough\n",
    "                    area_0 = area[parent_mask].sum()  # Parent area\n",
    "                    area_1 = area[child_mask].sum()\n",
    "                    min_area = np.minimum(area_0, area_1)\n",
    "                    overlap_area = area[parent_mask & child_mask].sum()\n",
    "                    \n",
    "                    if overlap_area / min_area < tracker.overlap_threshold:\n",
    "                        continue\n",
    "                    \n",
    "                    parent_masks_uint[parent_mask] = parent_iterator\n",
    "                    parent_ids[n_parents] = parent_id\n",
    "                    overlap_areas[n_parents] = overlap_area\n",
    "                    \n",
    "                    # Calculate centroid for this parent\n",
    "                    mask_area = area[parent_mask]\n",
    "                    weighted_coords = np.array([\n",
    "                        np.sum(mask_area * x[parent_mask]),\n",
    "                        np.sum(mask_area * y[parent_mask]),\n",
    "                        np.sum(mask_area * z[parent_mask])\n",
    "                    ], dtype=np.float32)\n",
    "                    \n",
    "                    norm = np.sqrt(np.sum(weighted_coords * weighted_coords))\n",
    "                                \n",
    "                    # Convert back to lat/lon\n",
    "                    parent_centroids[n_parents, 0] = np.degrees(np.arcsin(weighted_coords[2]/norm))\n",
    "                    parent_centroids[n_parents, 1] = np.degrees(np.arctan2(weighted_coords[1], weighted_coords[0]))\n",
    "                    \n",
    "                    # Fix longitude range to [-180, 180]\n",
    "                    if parent_centroids[n_parents, 1] > 180:\n",
    "                        parent_centroids[n_parents, 1] -= 360\n",
    "                    elif parent_centroids[n_parents, 1] < -180:\n",
    "                        parent_centroids[n_parents, 1] += 360\n",
    "                    \n",
    "                    parent_areas[n_parents] = area_0\n",
    "                    parent_iterator += 1\n",
    "                    n_parents += 1\n",
    "            \n",
    "            if n_parents < 2:  # Need at least 2 parents for merging\n",
    "                continue\n",
    "            \n",
    "            # Create new IDs for each partition\n",
    "            new_child_ids = np.arange(next_new_id, next_new_id + (n_parents - 1), dtype=np.int32)\n",
    "            child_ids = np.concatenate((np.array([child_id]), new_child_ids))\n",
    "            \n",
    "            # Record merge event\n",
    "            curr_merge_idx = merge_counts[t]\n",
    "            if curr_merge_idx > MAX_MERGES:\n",
    "                raise RuntimeError(f\"Reached maximum number of merges ({MAX_MERGES}) at timestep {t}\")\n",
    "            \n",
    "            merge_child_ids[t, curr_merge_idx, :n_parents] = child_ids[:n_parents]\n",
    "            merge_parent_ids[t, curr_merge_idx, :n_parents] = parent_ids[:n_parents]\n",
    "            merge_areas[t, curr_merge_idx, :n_parents] = overlap_areas[:n_parents]\n",
    "            merge_counts[t] += 1\n",
    "            has_merge[t] = True\n",
    "            \n",
    "            # Get new labels based on partitioning method\n",
    "            if tracker.nn_partitioning:\n",
    "                # Estimate max_area from number of cells\n",
    "                max_area = parent_areas.max() / tracker.mean_cell_area\n",
    "                max_distance = int(np.sqrt(max_area) * 2.0)\n",
    "                \n",
    "                new_labels_uint = partition_nn_unstructured_optimised(\n",
    "                    child_mask.copy(),\n",
    "                    parent_masks_uint.copy(),\n",
    "                    parent_centroids,\n",
    "                    neighbours_int.copy(),\n",
    "                    lat,\n",
    "                    lon,\n",
    "                    max_distance=max(max_distance, 20)*2\n",
    "                )\n",
    "                # Returned 'new_labels_uint' is just the index of the child_ids\n",
    "                new_labels = child_ids[new_labels_uint]\n",
    "                \n",
    "                # Force Number JIT Cleanup\n",
    "                new_labels_uint = None\n",
    "                \n",
    "            else:\n",
    "                new_labels = partition_centroid_unstructured(\n",
    "                    child_mask,\n",
    "                    parent_centroids,\n",
    "                    child_ids,\n",
    "                    lat,\n",
    "                    lon\n",
    "                )\n",
    "            \n",
    "            # Update slice data for subsequent merging in process_chunk\n",
    "            data_t[child_mask] = new_labels\n",
    "            \n",
    "            # Record Updates\n",
    "            spatial_indices_all = np.where(child_mask)[0]\n",
    "            child_mask = None\n",
    "            gc.collect()\n",
    "            \n",
    "            for new_id in child_ids[1:]:\n",
    "                update_idx = np.where(updates_ids[t] == -1)[0][0]  # Find next non-negative index in updates_ids\n",
    "                updates_ids[t, update_idx] = new_id\n",
    "                updates_array[t, spatial_indices_all[new_labels == new_id]] = update_idx\n",
    "            \n",
    "            next_new_id += n_parents - 1\n",
    "            \n",
    "            \n",
    "            # Find all child blobs in the next timestep that overlap with our newly labeled regions\n",
    "            new_merging_list = []\n",
    "            for new_id in child_ids:\n",
    "                parent_mask = (data_t == new_id)\n",
    "                if np.any(parent_mask):\n",
    "                    area_0 = area[parent_mask].sum()\n",
    "                    potential_children = np.unique(data_p1[parent_mask])\n",
    "                    \n",
    "                    for potential_child in potential_children[potential_children > 0]:\n",
    "                        potential_child_mask = (data_p1 == potential_child)\n",
    "                        area_1 = area[potential_child_mask].sum()\n",
    "                        min_area = min(area_0, area_1)\n",
    "                        overlap_area = area[parent_mask & potential_child_mask].sum()\n",
    "                        \n",
    "                        if overlap_area / min_area > tracker.overlap_threshold:\n",
    "                            new_merging_list.append(potential_child)\n",
    "            \n",
    "            # Add to processing queue if not already processed\n",
    "            if t < n_time - 1:\n",
    "                for new_blob_id in new_merging_list:\n",
    "                    if new_blob_id not in merging_blobs_list[t+1]:\n",
    "                        merging_blobs_list[t+1].append(new_blob_id)\n",
    "            else:\n",
    "                for new_blob_id in new_merging_list:\n",
    "                    if final_merge_count > MAX_MERGES:\n",
    "                        raise RuntimeError(f\"Reached maximum number of merges ({MAX_MERGES}) at timestep {t}\")\n",
    "                    \n",
    "                    # if new_blob_id is not in final_merging_blobs[t]\n",
    "                    if not np.any(final_merging_blobs[t][:final_merge_count] == new_blob_id):\n",
    "                        final_merging_blobs[t][final_merge_count] = new_blob_id\n",
    "                        final_merge_count += 1\n",
    "            \n",
    "                    \n",
    "    return (merge_child_ids, merge_parent_ids, merge_areas, merge_counts, \n",
    "                has_merge, updates_array, updates_ids, \n",
    "                final_merging_blobs)\n",
    "\n",
    "\n",
    "def update_blob_field_inplace(blob_id_field, id_lookup, updates_array, updates_ids, has_merge):\n",
    "    \"\"\"Update the blob field with chunk results using xarray operations.\n",
    "            N.B.: This is much more memory efficient because we don't need to make new copies of blob_id_field !\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    blob_id_field : xarray.DataArray\n",
    "        The full blob field to update\n",
    "    id_lookup : Dictionary\n",
    "        Dictionary mapping temporary IDs to new IDs\n",
    "    updates : xarray.DataArray\n",
    "        DataArray of Dictionaries containing updates: 'spatial_indices' for each 'new_label'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xarray.DataArray\n",
    "        Updated blob field\n",
    "    \"\"\"\n",
    "    \n",
    "    if not has_merge.any():  # If no merges -- then id_lookup is empty too\n",
    "        return blob_id_field\n",
    "    \n",
    "    def update_timeslice(data, updates, update_ids, lookup_values):\n",
    "        \"\"\"Process a single timeslice.\"\"\"\n",
    "        # Extract valid update IDs\n",
    "        valid_ids = update_ids[update_ids > -1]\n",
    "        if len(valid_ids) == 0:\n",
    "            return data\n",
    "            \n",
    "        # Create result array starting with original values\n",
    "        result = data.copy()\n",
    "        \n",
    "        # Apply each update\n",
    "        for idx, update_id in enumerate(valid_ids):\n",
    "            mask = updates == idx\n",
    "            if mask.any():\n",
    "                result = np.where(mask, lookup_values[update_id], result)\n",
    "                \n",
    "        return result\n",
    "    \n",
    "                \n",
    "    # Convert lookup dict to array for vectorized access\n",
    "    max_id = max(id_lookup.keys()) + 1\n",
    "    lookup_array = np.full(max_id, -1, dtype=np.int32)\n",
    "    for temp_id, new_id in id_lookup.items():\n",
    "        lookup_array[temp_id] = new_id\n",
    "    \n",
    "    result = xr.apply_ufunc(\n",
    "        update_timeslice,\n",
    "        blob_id_field,\n",
    "        updates_array,\n",
    "        updates_ids,\n",
    "        kwargs={'lookup_values': lookup_array},\n",
    "        input_core_dims=[[tracker.xdim],\n",
    "                        [tracker.xdim],\n",
    "                        ['update_idx']],\n",
    "        output_core_dims=[[tracker.xdim]],\n",
    "        vectorize=True, \n",
    "        dask='parallelized',\n",
    "        output_dtypes=[np.int32]\n",
    "    )\n",
    "    \n",
    "    #result = xr.where(has_merge, result, blob_id_field)\n",
    "    #del blob_id_field\n",
    "    \n",
    "    #result = result.persist(optimize_graph=True)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def merge_blobs_parallel_iteration(blob_id_field_unique, merging_blobs, global_id_counter):\n",
    "    \"\"\"Perform a single iteration of the parallel merging process.\"\"\"\n",
    "    \n",
    "    n_time = len(blob_id_field_unique[tracker.timedim])\n",
    "    \n",
    "    child_ids_iter = np.full((n_time, MAX_MERGES, MAX_CHILDREN), -1, dtype=np.int32)     # List of child ID arrays for this time\n",
    "    parent_ids_iter = np.full((n_time, MAX_MERGES, MAX_PARENTS), -1, dtype=np.int32)     # List of parent ID arrays for this time\n",
    "    merge_areas_iter = np.full((n_time, MAX_MERGES, MAX_PARENTS), -1, dtype=np.float32)  # List of areas for this time\n",
    "    merge_counts_iter = np.zeros(n_time, dtype=np.int32)\n",
    "    \n",
    "    neighbours_int = tracker.neighbours_int.chunk({tracker.xdim: -1, 'nv':-1})\n",
    "    \n",
    "    if tracker.verbosity > 0:    print(f\"Processing Parallel Iteration {iteration + 1} with {len(merging_blobs)} Merging Blobs...\")\n",
    "    \n",
    "    # Pre-compute the child_time_idx for merging_blobs\n",
    "    time_index_map = tracker.compute_id_time_dict(blob_id_field_unique, list(merging_blobs), global_id_counter)\n",
    "    if tracker.verbosity > 1:    print('  Finished Mapping Children to Time Indices.')\n",
    "    \n",
    "    # Create the uniform merging blobs array\n",
    "    max_merges = max(len([b for b in merging_blobs if time_index_map.get(b, -1) == t]) for t in range(n_time))\n",
    "    uniform_merging_blobs_array = np.zeros((n_time, max_merges), dtype=np.int64)\n",
    "    for t in range(n_time):\n",
    "        blobs_at_t = [b for b in merging_blobs if time_index_map.get(b, -1) == t]\n",
    "        if blobs_at_t:  # Only fill if there are blobs at this time\n",
    "            uniform_merging_blobs_array[t, :len(blobs_at_t)] = np.array(blobs_at_t, dtype=np.int64)\n",
    "\n",
    "    merging_blobs_da = xr.DataArray(\n",
    "        uniform_merging_blobs_array,\n",
    "        dims=[tracker.timedim, 'merges'],\n",
    "        coords={tracker.timedim: blob_id_field_unique[tracker.timedim]})\n",
    "    \n",
    "    next_id_offsets = np.arange(n_time) * max_merges * tracker.timechunks + global_id_counter    \n",
    "    # N.B.: We also need to account for possibility of newly-split blobs then creating more than max_merges by the end of the iteration through the chunk\n",
    "    #         !!! This is likely the root cause of any errors such as \"ID needs to be contiguous/continuous/full/unrepeated\"\n",
    "    next_id_offsets_da = xr.DataArray(next_id_offsets,\n",
    "                                    dims=[tracker.timedim],\n",
    "                                    coords={tracker.timedim: blob_id_field_unique[tracker.timedim]})\n",
    "    \n",
    "    blob_id_field_unique_p1 = blob_id_field_unique.shift({tracker.timedim: -1}, fill_value=0)\n",
    "    blob_id_field_unique_m1 = blob_id_field_unique.shift({tracker.timedim: 1}, fill_value=0)\n",
    "    \n",
    "    # Align chunks\n",
    "    blob_id_field_unique_m1 = blob_id_field_unique_m1.chunk({tracker.timedim: tracker.timechunks})\n",
    "    blob_id_field_unique_p1 = blob_id_field_unique_p1.chunk({tracker.timedim: tracker.timechunks})\n",
    "    merging_blobs_da = merging_blobs_da.chunk({tracker.timedim: tracker.timechunks})\n",
    "    next_id_offsets_da = next_id_offsets_da.chunk({tracker.timedim: tracker.timechunks})\n",
    "    \n",
    "    results = xr.apply_ufunc(process_chunk,\n",
    "                            blob_id_field_unique_m1,\n",
    "                            blob_id_field_unique_p1,\n",
    "                            merging_blobs_da,\n",
    "                            next_id_offsets_da,\n",
    "                            tracker.lat,\n",
    "                            tracker.lon,\n",
    "                            tracker.cell_area,\n",
    "                            neighbours_int,\n",
    "                            input_core_dims=[[tracker.xdim], [tracker.xdim], ['merges'], [], [tracker.xdim], [tracker.xdim], [tracker.xdim], ['nv', tracker.xdim]],\n",
    "                            output_core_dims=[['merge', 'parent'], ['merge', 'parent'], \n",
    "                                            ['merge', 'parent'], [],\n",
    "                                            [], [tracker.xdim], ['update_idx'], ['merge']],\n",
    "                            output_dtypes=[np.int32, np.int32, np.float32, np.int16, \n",
    "                                        np.bool_, np.uint8, np.int32, np.int32],\n",
    "                            dask_gufunc_kwargs={'output_sizes': {\n",
    "                                                                'merge': MAX_MERGES,\n",
    "                                                                'parent': MAX_PARENTS,\n",
    "                                                                'update_idx': 255\n",
    "                                                            }},\n",
    "                            vectorize=False,\n",
    "                            dask='parallelized')\n",
    "\n",
    "    # Unpack & persist results\n",
    "    (merge_child_ids, merge_parent_ids, merge_areas, merge_counts,\n",
    "        has_merge, updates_array, updates_ids, final_merging_blobs) = results\n",
    "    \n",
    "    results = persist(merge_child_ids, merge_parent_ids, merge_areas, merge_counts,\n",
    "                        has_merge, updates_array, updates_ids, final_merging_blobs\n",
    "        )\n",
    "    (merge_child_ids, merge_parent_ids, merge_areas, merge_counts, \n",
    "        has_merge, updates_array, updates_ids, final_merging_blobs) = results\n",
    "    \n",
    "    \n",
    "    has_merge = has_merge.compute()\n",
    "    time_indices = np.where(has_merge)[0]\n",
    "    \n",
    "    # Clean up temporary arrays\n",
    "    del blob_id_field_unique_p1, blob_id_field_unique_m1, merging_blobs_da, next_id_offsets_da\n",
    "    gc.collect()\n",
    "    if tracker.verbosity > 1:    print('  Finished Batch Processing Step.')\n",
    "    \n",
    "    \n",
    "    ### Global Consolidatation of Data ###\n",
    "    \n",
    "    # 1:  Collect all temporary IDs and create global mapping\n",
    "    all_temp_ids = np.unique(merge_child_ids.where(merge_child_ids >= global_id_counter, other=0).compute().values)\n",
    "    all_temp_ids = all_temp_ids[all_temp_ids>0] # Remove the 0...\n",
    "    if not all_temp_ids.size:  # If no temporary IDs exist\n",
    "        id_lookup = {}\n",
    "    else:            \n",
    "        id_lookup = {temp_id: np.int32(new_id) for temp_id, new_id in zip(\n",
    "            all_temp_ids,\n",
    "            range(global_id_counter, global_id_counter + len(all_temp_ids))\n",
    "        )}\n",
    "        global_id_counter += len(all_temp_ids)\n",
    "    \n",
    "    if tracker.verbosity > 1:    print('  Finished Consolidation Step 1: Temporary ID Mapping')\n",
    "    \n",
    "    # 2:  Update Field with new IDs\n",
    "    blob_id_field_unique = update_blob_field_inplace(blob_id_field_unique, id_lookup, updates_array, updates_ids, has_merge)\n",
    "    blob_id_field_unique = blob_id_field_unique.chunk({tracker.timedim: tracker.timechunks}) # Rechunk to avoid accumulating chunks...\n",
    "    del updates_array, updates_ids\n",
    "    gc.collect()\n",
    "    if tracker.verbosity > 1:    print('  Finished Consolidation Step 2: Data Field Update.')\n",
    "    \n",
    "    # 3:  Update Merge Events\n",
    "    new_merging_blobs = set()\n",
    "    merge_counts = merge_counts.compute()\n",
    "    for t in time_indices:\n",
    "        count = merge_counts.isel({tracker.timedim: t}).item()\n",
    "        if count > 0:\n",
    "            merge_counts_iter[t] = count\n",
    "            \n",
    "            # Extract valid IDs and areas\n",
    "            for merge_idx in range(count):\n",
    "                child_ids = merge_child_ids.isel({tracker.timedim: t, 'merge': merge_idx}).compute().values\n",
    "                child_ids = child_ids[child_ids >= 0]\n",
    "                \n",
    "                parent_ids = merge_parent_ids.isel({tracker.timedim: t, 'merge': merge_idx}).compute().values\n",
    "                areas = merge_areas.isel({tracker.timedim: t, 'merge': merge_idx}).compute().values\n",
    "                valid_mask = parent_ids >= 0\n",
    "                parent_ids = parent_ids[valid_mask]\n",
    "                areas = areas[valid_mask]\n",
    "                \n",
    "                # Map IDs and add to merge events\n",
    "                mapped_child_ids = [id_lookup.get(id_.item(), id_.item()) for id_ in child_ids]\n",
    "                mapped_parent_ids = [id_lookup.get(id_.item(), id_.item()) for id_ in parent_ids]\n",
    "                \n",
    "                # Store in pre-allocated arrays\n",
    "                child_ids_iter[t, merge_idx, :len(mapped_child_ids)] = mapped_child_ids\n",
    "                parent_ids_iter[t, merge_idx, :len(mapped_parent_ids)] = mapped_parent_ids\n",
    "                merge_areas_iter[t, merge_idx, :len(areas)] = areas\n",
    "    \n",
    "    \n",
    "    final_merging_blobs = final_merging_blobs.compute().values\n",
    "    final_merging_blobs = final_merging_blobs[final_merging_blobs > 0]\n",
    "    mapped_final_blobs = [id_lookup.get(id_, id_) for id_ in final_merging_blobs]\n",
    "    new_merging_blobs.update(mapped_final_blobs)\n",
    "    \n",
    "    if tracker.verbosity > 1:    print('  Finished Consolidation Step 3: Merge List Dictionary Consolidation.')\n",
    "    \n",
    "    \n",
    "    # Clean up memory\n",
    "    del merge_child_ids, merge_parent_ids, merge_areas, merge_counts, has_merge\n",
    "    gc.collect()\n",
    "                \n",
    "    \n",
    "    return (blob_id_field_unique,  \n",
    "            (child_ids_iter, parent_ids_iter, merge_areas_iter, merge_counts_iter),\n",
    "            new_merging_blobs, global_id_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile List of Overlapping Blob ID Pairs Across Time\n",
    "overlap_blobs_list = tracker.find_overlapping_blobs(blob_id_field_unique, blob_props)  # List blob pairs that overlap by at least overlap_threshold percent\n",
    "if tracker.verbosity > 0:    print('Finished Finding Overlapping Blobs.')\n",
    "\n",
    "# Find initial merging blobs\n",
    "unique_children, children_counts = np.unique(overlap_blobs_list[:, 1], return_counts=True)\n",
    "merging_blobs = set(unique_children[children_counts > 1].astype(np.int32))\n",
    "del overlap_blobs_list\n",
    "\n",
    "## Process chunks iteratively until no new merging blobs remain\n",
    "iteration = 0\n",
    "max_iterations = 20  # i.e. 80 days (maximum event duration...)\n",
    "processed_chunks = set()\n",
    "global_id_counter = blob_props.ID.max().item() + 1\n",
    "\n",
    "# Initialise global merge event tracking\n",
    "global_child_ids = []\n",
    "global_parent_ids = []\n",
    "global_merge_areas = []\n",
    "global_merge_tidx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id_field_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "while merging_blobs and iteration < max_iterations:\n",
    "    \n",
    "    blob_id_field_new, merge_data_iter, new_merging_blobs, global_id_counter = merge_blobs_parallel_iteration(blob_id_field_unique, merging_blobs, global_id_counter)\n",
    "    child_ids_iter, parent_ids_iter, merge_areas_iter, merge_counts_iter = merge_data_iter\n",
    "    \n",
    "    # Merge all_merge_events_chunk into all_merge_events\n",
    "    for t in range(len(merge_counts_iter)):\n",
    "        count = merge_counts_iter[t]\n",
    "        if count > 0:\n",
    "            for merge_idx in range(count):\n",
    "                # Get valid children\n",
    "                children = child_ids_iter[t, merge_idx]\n",
    "                children = children[children >= 0]\n",
    "                \n",
    "                # Get valid parents and areas\n",
    "                parents = parent_ids_iter[t, merge_idx]\n",
    "                areas = merge_areas_iter[t, merge_idx]\n",
    "                valid_mask = parents >= 0\n",
    "                parents = parents[valid_mask]\n",
    "                areas = areas[valid_mask]\n",
    "                \n",
    "                if len(children) > 0 and len(parents) > 0:\n",
    "                    global_child_ids.append(children)\n",
    "                    global_parent_ids.append(parents)\n",
    "                    global_merge_areas.append(areas)\n",
    "                    global_merge_tidx.append(t)\n",
    "    \n",
    "    # Prepare for next iteration\n",
    "    merging_blobs = new_merging_blobs - processed_chunks\n",
    "    processed_chunks.update(new_merging_blobs)\n",
    "    iteration += 1\n",
    "    \n",
    "    if not iteration % 3 or not merging_blobs or iteration == max_iterations:  # Every few iterations & on last iteration\n",
    "        blob_id_field_unique = tracker.refresh_dask_graph(blob_id_field_new)\n",
    "    else:\n",
    "        blob_id_field_unique = blob_id_field_new #.persist()\n",
    "    del blob_id_field_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66a034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd00bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id_field_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4ba44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## WHILE.......\n",
    "\n",
    "blob_id_field_new, merge_data_iter, new_merging_blobs, global_id_counter = merge_blobs_parallel_iteration(blob_id_field_unique, merging_blobs, global_id_counter)\n",
    "\n",
    "child_ids_iter, parent_ids_iter, merge_areas_iter, merge_counts_iter = merge_data_iter\n",
    "\n",
    "# Merge all_merge_events_chunk into all_merge_events\n",
    "for t in range(len(merge_counts_iter)):\n",
    "    count = merge_counts_iter[t]\n",
    "    if count > 0:\n",
    "        for merge_idx in range(count):\n",
    "            # Get valid children\n",
    "            children = child_ids_iter[t, merge_idx]\n",
    "            children = children[children >= 0]\n",
    "            \n",
    "            # Get valid parents and areas\n",
    "            parents = parent_ids_iter[t, merge_idx]\n",
    "            areas = merge_areas_iter[t, merge_idx]\n",
    "            valid_mask = parents >= 0\n",
    "            parents = parents[valid_mask]\n",
    "            areas = areas[valid_mask]\n",
    "            \n",
    "            if len(children) > 0 and len(parents) > 0:\n",
    "                global_child_ids.append(children)\n",
    "                global_parent_ids.append(parents)\n",
    "                global_merge_areas.append(areas)\n",
    "                global_merge_tidx.append(t)\n",
    "\n",
    "\n",
    "# Prepare for next iteration\n",
    "merging_blobs = new_merging_blobs - processed_chunks\n",
    "processed_chunks.update(new_merging_blobs)\n",
    "iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id_field_unique = blob_id_field_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ca654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d772972",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id_field_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b91421",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id_field_unique = tracker.refresh_dask_graph(blob_id_field_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e78c5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c43da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename xarray DataArray field to 'blob_id_field'\n",
    "blob_id_field_new.name = 'blob_id_field'\n",
    "blob_id_field_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id_field_new.to_zarr('/scratch/b/b382615/mhws/TEMP/blob_id_field.zarr', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c43da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del blob_id_field_new\n",
    "del blob_id_field_unique\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_id_field_unique = xr.open_zarr('/scratch/b/b382615/mhws/TEMP/blob_id_field.zarr', chunks={})\n",
    "blob_id_field_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e54c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd115c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccd21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = blobs.compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Tracked Blobs to `zarr` for more efficient parallel I/O\n",
    "\n",
    "file_name = Path('/scratch') / getuser()[0] / getuser() / 'mhws' / 'MHWs_tracked_unstruct.zarr'\n",
    "blobs.to_zarr(file_name, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
