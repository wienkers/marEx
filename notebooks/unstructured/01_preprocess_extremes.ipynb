{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process global _daily_ SST on _Native_ 5km Unstructured Grid using `hot_to_blOb` to extract binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d21965",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "1. Compute Normalised Detrended Anomaly (cf. `hot_to_blOb.py::compute_normalised_anomaly()`)\n",
    "2. Identify Extreme Values (i.e. above 95th percentile) using new histogram-based parallel quantile calculation\n",
    "\n",
    "N.B.: Exploits parallelised `Dask` operations with optimised chunking using `flox` \\\n",
    "N.N.B.: This example using 40 years of Daily outputs at 5km resolution on an Unstructured Grid (15 million cells) takes ~10 minutes on 512 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import intake\n",
    "import numpy as np\n",
    "from getpass import getuser\n",
    "from pathlib import Path\n",
    "\n",
    "import spot_the_blOb.hot_to_blOb as hot\n",
    "import spot_the_blOb.helper as hpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a5e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Distributed Dask Cluster\n",
    "client = hpc.StartDistributedCluster(n_workers=512, workers_per_node=64, runtime=20, node_memory=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d8061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 40 years of Daily EERIE ICON data\n",
    "\n",
    "cat = intake.open_catalog(\"https://raw.githubusercontent.com/eerie-project/intake_catalogues/main/eerie.yaml\")\n",
    "expid = 'eerie-control-1950'\n",
    "version = 'v20231106'\n",
    "model = 'icon-esm-er'\n",
    "gridspec = 'native'\n",
    "\n",
    "dat = cat['dkrz.disk.model-output'][model][expid][version]['ocean'][gridspec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d52604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data directly into slightly larger time chunks\n",
    "sst = dat['2d_daily_mean'](chunks={'time':200,'ncells':'auto'}).to_dask().to.isel(depth=0)\n",
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd3d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the grid & neighbours\n",
    "grid2d = dat['2d_grid'](chunks={}).to_dask().rename({'cell':'ncells'})\n",
    "neighbours = grid2d.neighbor_cell_index.rename({'clat':'lat', 'clon':'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389349a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data using `hot_to_blOb` helper functions:\n",
    "\n",
    "extreme_events_ds = hot.preprocess_data(sst, std_normalise=False, threshold_percentile=95, \n",
    "                                        exact_percentile=False,                         # Use a histogram-based method to estimate the percentile value (within 0.025C)\n",
    "                                        dask_chunks={'time':2},                         # Need to use smaller chunks in time to account for larger spatial dimension\n",
    "                                        neighbours = neighbours,                        # Pass information about neighbours to be used in subsequent processing\n",
    "                                        dimensions={'time':'time', 'xdim':'ncells'})    # Not specifying 'ydim' tells hot_to_blOb that it is an unstructured grid\n",
    "extreme_events_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to `zarr` for more efficient paralledl I/O\n",
    "file_name = Path('/scratch') / getuser()[0] / getuser() / 'mhws' / 'extreme_events_binary_unstruct.zarr'\n",
    "encoding = {var: {'compressor': None} for var in extreme_events_ds.data_vars}\n",
    "extreme_events_ds.to_zarr(file_name, mode='w', encoding=encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
